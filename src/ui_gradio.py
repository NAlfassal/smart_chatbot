"""
Improved Gradio Application for SFDA Cosmetics Chatbot.

ÙˆØ§Ø¬Ù‡Ø© Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¹Ù†:
- Ù„ÙˆØ§Ø¦Ø­ Ø§Ù„ØªØ¬Ù…ÙŠÙ„ (PDF)       category=regulation
- Ù…Ø­Ø¸ÙˆØ±Ø§Øª Ø§Ù„ØªØ¬Ù…ÙŠÙ„          category=banned
- Ø§Ù„Ø£Ø³Ø³ (GDP)              category=gdp

Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… RAG (Retrieval Augmented Generation)
"""

import os
import re
import sys
import traceback
from typing import List, Optional, Iterator

import gradio as gr
from langchain_openai import ChatOpenAI
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain_core.documents import Document
from langchain_core.messages import HumanMessage

from src.utils.logger import get_logger
from src import config

logger = get_logger("sfda_app")


# âœ… (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) Ù„Ùˆ ØªØ­ØªØ§Ø¬ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ù…Ù† Ø£ÙŠ Ù…ÙƒØ§Ù† Ø¨Ø¯ÙˆÙ† Ù…Ø´Ø§ÙƒÙ„ Ø§Ø³ØªÙŠØ±Ø§Ø¯
ROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if ROOT_DIR not in sys.path:
    sys.path.insert(0, ROOT_DIR)


# ---------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------
class ArabicArticleParser:
    """Handles parsing and conversion of Arabic article numbers."""

    AR_WORD_TO_NUM = {
        "Ø§Ù„Ø£ÙˆÙ„Ù‰": "1", "Ø§Ù„Ø§ÙˆÙ„Ù‰": "1",
        "Ø§Ù„Ø«Ø§Ù†ÙŠØ©": "2",
        "Ø§Ù„Ø«Ø§Ù„Ø«Ø©": "3",
        "Ø§Ù„Ø±Ø§Ø¨Ø¹Ø©": "4",
        "Ø§Ù„Ø®Ø§Ù…Ø³Ø©": "5",
        "Ø§Ù„Ø³Ø§Ø¯Ø³Ø©": "6",
        "Ø§Ù„Ø³Ø§Ø¨Ø¹Ø©": "7",
        "Ø§Ù„Ø«Ø§Ù…Ù†Ø©": "8",
        "Ø§Ù„ØªØ§Ø³Ø¹Ø©": "9",
        "Ø§Ù„Ø¹Ø§Ø´Ø±Ø©": "10",
        "Ø§Ù„Ø­Ø§Ø¯ÙŠØ© Ø¹Ø´Ø±": "11", "Ø§Ù„Ø­Ø§Ø¯ÙŠØ© Ø¹Ø´Ø±Ø©": "11",
        "Ø§Ù„Ø«Ø§Ù†ÙŠØ© Ø¹Ø´Ø±": "12", "Ø§Ù„Ø«Ø§Ù†ÙŠØ© Ø¹Ø´Ø±Ø©": "12",
        "Ø§Ù„Ø«Ø§Ù„Ø«Ø© Ø¹Ø´Ø±": "13", "Ø§Ù„Ø«Ø§Ù„Ø«Ø© Ø¹Ø´Ø±Ø©": "13",
        "Ø§Ù„Ø±Ø§Ø¨Ø¹Ø© Ø¹Ø´Ø±": "14", "Ø§Ù„Ø±Ø§Ø¨Ø¹Ø© Ø¹Ø´Ø±Ø©": "14",
        "Ø§Ù„Ø®Ø§Ù…Ø³Ø© Ø¹Ø´Ø±": "15", "Ø§Ù„Ø®Ø§Ù…Ø³Ø© Ø¹Ø´Ø±Ø©": "15",
        "Ø§Ù„Ø³Ø§Ø¯Ø³Ø© Ø¹Ø´Ø±": "16", "Ø§Ù„Ø³Ø§Ø¯Ø³Ø© Ø¹Ø´Ø±Ø©": "16",
        "Ø§Ù„Ø³Ø§Ø¨Ø¹Ø© Ø¹Ø´Ø±": "17", "Ø§Ù„Ø³Ø§Ø¨Ø¹Ø© Ø¹Ø´Ø±Ø©": "17",
        "Ø§Ù„Ø«Ø§Ù…Ù†Ø© Ø¹Ø´Ø±": "18", "Ø§Ù„Ø«Ø§Ù…Ù†Ø© Ø¹Ø´Ø±Ø©": "18",
        "Ø§Ù„ØªØ§Ø³Ø¹Ø© Ø¹Ø´Ø±": "19", "Ø§Ù„ØªØ§Ø³Ø¹Ø© Ø¹Ø´Ø±Ø©": "19",
        "Ø§Ù„Ø¹Ø´Ø±ÙˆÙ†": "20",
        "Ø§Ù„Ø­Ø§Ø¯ÙŠØ© ÙˆØ§Ù„Ø¹Ø´Ø±ÙˆÙ†": "21",
        "Ø§Ù„Ø«Ø§Ù†ÙŠØ© ÙˆØ§Ù„Ø¹Ø´Ø±ÙˆÙ†": "22",
        "Ø§Ù„Ø«Ø§Ù„Ø«Ø© ÙˆØ§Ù„Ø¹Ø´Ø±ÙˆÙ†": "23",
        "Ø§Ù„Ø±Ø§Ø¨Ø¹Ø© ÙˆØ§Ù„Ø¹Ø´Ø±ÙˆÙ†": "24",
        "Ø§Ù„Ø®Ø§Ù…Ø³Ø© ÙˆØ§Ù„Ø¹Ø´Ø±ÙˆÙ†": "25",
        "Ø§Ù„Ø³Ø§Ø¯Ø³Ø© ÙˆØ§Ù„Ø¹Ø´Ø±ÙˆÙ†": "26",
        "Ø§Ù„Ø³Ø§Ø¨Ø¹Ø© ÙˆØ§Ù„Ø¹Ø´Ø±ÙˆÙ†": "27",
        "Ø§Ù„Ø«Ø§Ù…Ù†Ø© ÙˆØ§Ù„Ø¹Ø´Ø±ÙˆÙ†": "28",
        "Ø§Ù„ØªØ§Ø³Ø¹Ø© ÙˆØ§Ù„Ø¹Ø´Ø±ÙˆÙ†": "29",
        "Ø§Ù„Ø«Ù„Ø§Ø«ÙˆÙ†": "30",
    }

    @classmethod
    def normalize_article_to_num(cls, article_value: str) -> Optional[str]:
        if article_value is None:
            return None

        s = str(article_value).strip()
        s = s.replace("Ù€", "")
        s = re.sub(r"\s{2,}", " ", s)
        s = re.sub(r"^\s*Ø§Ù„Ù…Ø§Ø¯Ø©\s+", "", s).strip()

        if re.fullmatch(r"\d+", s):
            return s

        if s in cls.AR_WORD_TO_NUM:
            return cls.AR_WORD_TO_NUM[s]

        words = s.split()
        for n in (4, 3, 2, 1):
            if len(words) >= n:
                cand = " ".join(words[:n])
                if cand in cls.AR_WORD_TO_NUM:
                    return cls.AR_WORD_TO_NUM[cand]
        return None

    @classmethod
    def extract_article_number(cls, text: str) -> Optional[str]:
        text = text or ""

        m = re.search(r"Ø§Ù„Ù…Ø§Ø¯Ø©\s+(\d+)", text)
        if m:
            return m.group(1)

        m = re.search(r"Ø§Ù„Ù…Ø§Ø¯Ø©\s+([^\nØŒ,.ØŸ!]+)", text)
        if not m:
            return None

        phrase = re.sub(r"\s{2,}", " ", m.group(1).replace("Ù€", "")).strip()
        phrase = re.sub(r"^\s*Ø§Ù„Ù…Ø§Ø¯Ø©\s+", "", phrase).strip()

        if phrase in cls.AR_WORD_TO_NUM:
            return cls.AR_WORD_TO_NUM[phrase]

        words = phrase.split()
        for n in (4, 3, 2, 1):
            if len(words) >= n:
                cand = " ".join(words[:n])
                if cand in cls.AR_WORD_TO_NUM:
                    return cls.AR_WORD_TO_NUM[cand]
        return None


class TextFormatter:
    """Handles text formatting and cleaning operations."""

    @staticmethod
    def clean_repeated_characters(text: str) -> str:
        return re.sub(r"(.)\1{2,}", r"\1", text or "")

    @staticmethod
    def merge_spaced_arabic_letters(text: str) -> str:
        if not text:
            return ""
        t = text
        for _ in range(3):
            t = re.sub(
                r"(?<![Ø¡-ÙŠ])((?:[Ø¡-ÙŠ]\s+){2,}[Ø¡-ÙŠ])(?![Ø¡-ÙŠ])",
                lambda m: m.group(1).replace(" ", ""),
                t,
            )
        return t

    @staticmethod
    def pretty_arabic_text(text: str) -> str:
        if not text:
            return ""
        t = TextFormatter.merge_spaced_arabic_letters(text)
        t = t.replace("\r\n", "\n").replace("\r", "\n")
        t = t.replace("Ù€", "")
        t = re.sub(r"[ \t]+", " ", t)
        t = re.sub(r"\n{3,}", "\n\n", t)
        return t.strip()


class SourceDisplayManager:
    """Display sources based on metadata category (NOT filename)."""

    @staticmethod
    def display_source_name_from_doc(doc: Document) -> str:
        cat = (doc.metadata.get("category") or "").lower().strip()

        if cat == "banned":
            return "Ù…Ø­Ø¸ÙˆØ±Ø§Øª Ø§Ù„ØªØ¬Ù…ÙŠÙ„"
        if cat == "regulation":
            return "Ù„ÙˆØ§Ø¦Ø­ Ø§Ù„ØªØ¬Ù…ÙŠÙ„"
        if cat in ("gdp", "guidelines", "gdp_guidelines"):
            return "Ø§Ù„Ø£Ø³Ø³ (Ø§Ù„ØªÙˆØ²ÙŠØ¹ ÙˆØ§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø¬ÙŠØ¯Ø©)"

        raw = doc.metadata.get("source", doc.metadata.get("source_file", "N/A"))
        return os.path.basename(raw or "N/A").strip() or "Ù…ØµØ§Ø¯Ø± Ø¥Ø¶Ø§ÙÙŠØ©"

    @staticmethod
    def sources_footer_once(docs: List[Document], chosen_sources_ui: List[str]) -> str:
        if chosen_sources_ui and set(chosen_sources_ui) == {"Ù…Ø­Ø¸ÙˆØ±Ø§Øª Ø§Ù„ØªØ¬Ù…ÙŠÙ„"}:
            return "\n\n**Ø§Ù„Ù…ØµØ¯Ø±:** Ù…Ø­Ø¸ÙˆØ±Ø§Øª Ø§Ù„ØªØ¬Ù…ÙŠÙ„"

        seen = set()
        sources = []
        for d in docs:
            name = SourceDisplayManager.display_source_name_from_doc(d)
            if name and name not in seen:
                seen.add(name)
                sources.append(name)

        return "\n\n**Ø§Ù„Ù…ØµØ¯Ø±:** " + ("ØŒ ".join(sources) if sources else "N/A")


# ---------------------------------------------------------------------
# Main Chatbot
# ---------------------------------------------------------------------
class SFDAChatbot:
    """Main chatbot class handling RAG operations."""

    def __init__(self):
        logger.info("Initializing SFDA Chatbot...")

        if not getattr(config, "OPENROUTER_API_KEY", None) and not getattr(config, "OPENAI_API_KEY", None):
            raise ValueError("OPENROUTER_API_KEY or OPENAI_API_KEY not found in .env file")

        logger.info("Loading embedding model...")
        self.embeddings_model = HuggingFaceEmbeddings(
            model_name=config.EMBEDDING_MODEL,
            model_kwargs={"device": config.EMBEDDING_DEVICE},
        )

        logger.info("Initializing LLM...")
        self.llm = ChatOpenAI(
            model=config.LLM_MODEL,
            temperature=config.LLM_TEMPERATURE,
            api_key=(config.OPENROUTER_API_KEY or config.OPENAI_API_KEY),
            base_url=config.LLM_BASE_URL,
            max_tokens=config.LLM_MAX_TOKENS,
        )

        logger.info("Loading vector store...")
        self.vector_store = Chroma(
            collection_name=config.COLLECTION_NAME,
            embedding_function=self.embeddings_model,
            persist_directory=str(config.CHROMA_PATH),
        )

        try:
            count = self.vector_store._collection.count()
            logger.info(f"Vector store loaded. Document count: {count}")
        except Exception as e:
            logger.warning(f"Could not get vector store count: {e}")

        logger.info("âœ… Chatbot initialized successfully")

    def get_article_doc(self, article_num: str) -> Optional[Document]:
        target = str(article_num).strip()

        try:
            docs = self.vector_store.similarity_search(
                query=f"Ø§Ù„Ù…Ø§Ø¯Ø© {target}",
                k=3,
                filter={"$and": [{"article": target}, {"category": "regulation"}]},
            )
            if docs:
                return docs[0]
        except Exception as e:
            logger.debug(f"Regulation filter search failed: {e}")

        try:
            docs = self.vector_store.similarity_search(
                query=f"Ø§Ù„Ù…Ø§Ø¯Ø© {target}",
                k=3,
                filter={"article": target},
            )
            if docs:
                return docs[0]
        except Exception as e:
            logger.debug(f"Article filter search failed: {e}")

        return None

    def format_article_output(self, doc: Document) -> str:
        art_num = ArabicArticleParser.normalize_article_to_num(doc.metadata.get("article", "")) or ""
        title = f"Ù†Øµ Ø§Ù„Ù…Ø§Ø¯Ø© ({art_num}) Ù…Ù† Ù„ÙˆØ§Ø¦Ø­ Ø§Ù„ØªØ¬Ù…ÙŠÙ„" if art_num else "Ù†Øµ Ø§Ù„Ù…Ø§Ø¯Ø© Ù…Ù† Ù„ÙˆØ§Ø¦Ø­ Ø§Ù„ØªØ¬Ù…ÙŠÙ„"
        body = TextFormatter.pretty_arabic_text(doc.page_content)

        if art_num:
            body = re.sub(rf"^\s*Ø§Ù„Ù…Ø§Ø¯Ø©\s*{re.escape(art_num)}\s*\n+", "", body)
            body = re.sub(rf"^\s*Ø§Ù„Ù…Ø§Ø¯Ø©\s*{re.escape(art_num)}\s*[:ï¼š]?\s*", "", body)

        return f"**{title}**\n\n{body}".strip()

    def build_retriever(self, ui_choices: List[str]):
        if not ui_choices:
            return self.vector_store.as_retriever(search_kwargs={"k": config.RETRIEVAL_K})

        selected_categories = []
        for ch in ui_choices:
            if ch == "Ù„ÙˆØ§Ø¦Ø­ Ø§Ù„ØªØ¬Ù…ÙŠÙ„ (PDF)":
                selected_categories.append("regulation")
            elif ch == "Ù…Ø­Ø¸ÙˆØ±Ø§Øª Ø§Ù„ØªØ¬Ù…ÙŠÙ„":
                selected_categories.append("banned")
            elif ch == "Ø§Ù„Ø£Ø³Ø³ (GDP)":
                selected_categories.append("gdp")

        if not selected_categories or len(selected_categories) >= 3:
            return self.vector_store.as_retriever(search_kwargs={"k": config.RETRIEVAL_K})

        if len(selected_categories) == 1:
            return self.vector_store.as_retriever(
                search_kwargs={"k": config.RETRIEVAL_K, "filter": {"category": selected_categories[0]}}
            )

        or_filter = {"$or": [{"category": c} for c in selected_categories]}
        return self.vector_store.as_retriever(search_kwargs={"k": config.RETRIEVAL_K, "filter": or_filter})

    @staticmethod
    def build_knowledge(docs: List[Document]) -> str:
        parts = []
        for d in docs:
            src = SourceDisplayManager.display_source_name_from_doc(d)
            snippet = TextFormatter.pretty_arabic_text(d.page_content)[:1400]
            parts.append(f"[{src}]\n{snippet}")
        return "\n\n".join(parts)

    def stream_response_core(self, message: str, source_choices: List[str]) -> Iterator[str]:
        message = (message or "").strip()
        if not message:
            yield "Ø§ÙƒØªØ¨ÙŠ Ø³Ø¤Ø§Ù„Ùƒ."
            return

        try:
            art_num = ArabicArticleParser.extract_article_number(message)
            if art_num:
                if source_choices and set(source_choices) == {"Ù…Ø­Ø¸ÙˆØ±Ø§Øª Ø§Ù„ØªØ¬Ù…ÙŠÙ„"}:
                    yield "Ø¹Ø°Ø±Ù‹Ø§ØŒ Ø³Ø¤Ø§Ù„ **Ø§Ù„Ù…Ø§Ø¯Ø©** ÙŠÙƒÙˆÙ† Ø¶Ù…Ù† **Ù„ÙˆØ§Ø¦Ø­ Ø§Ù„ØªØ¬Ù…ÙŠÙ„ (PDF)**. ÙØ¹Ù‘Ù„ÙŠ Ø®ÙŠØ§Ø± Ø§Ù„Ù„ÙˆØ§Ø¦Ø­."
                    return

                doc = self.get_article_doc(art_num)
                if not doc:
                    yield f"Ø¹Ø°Ø±Ù‹Ø§ØŒ Ù„Ù… Ø£Ø¬Ø¯ Ù†ØµÙ‹Ø§ ØµØ±ÙŠØ­Ù‹Ø§ Ù„Ù„Ù…Ø§Ø¯Ø© Ø±Ù‚Ù… {art_num} Ø¯Ø§Ø®Ù„ Ù„ÙˆØ§Ø¦Ø­ Ø§Ù„ØªØ¬Ù…ÙŠÙ„."
                    return

                answer = self.format_article_output(doc)
                answer += SourceDisplayManager.sources_footer_once([doc], source_choices)
                yield answer
                return

            retriever = self.build_retriever(source_choices)
            retrieved_docs = retriever.get_relevant_documents(message)

            if not retrieved_docs:
                yield "Ù„Ù… Ø£Ø¬Ø¯ Ù†ØµÙ‹Ø§ ØµØ±ÙŠØ­Ù‹Ø§ ÙÙŠ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…ØªØ§Ø­Ø© ÙŠØ¬ÙŠØ¨ Ø¹Ù† Ø°Ù„Ùƒ."
                return

            top_docs = retrieved_docs[:3]
            knowledge = self.build_knowledge(top_docs)

            generation_prompt = f"""
ROLE:
Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù…ØªØ«Ø§Ù„ ÙŠØ¹ØªÙ…Ø¯ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø±ÙÙ‚Ø©.

RULES (Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹):
- Ù„Ø§ ØªØ¶Ù Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø© Ù…Ù† Ø®Ø§Ø±Ø¬ "Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©".
- Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ù†ØµØ§Ù‹ ØµØ±ÙŠØ­Ø§Ù‹ ÙŠØ¬ÙŠØ¨ Ø¹Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ØŒ Ù‚Ù„: "Ù„Ù… Ø£Ø¬Ø¯ Ù†ØµØ§Ù‹ ØµØ±ÙŠØ­Ø§Ù‹ ÙÙŠ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…Ø±ÙÙ‚Ø© ÙŠØ¬ÙŠØ¨ Ø¹Ù† Ø°Ù„Ùƒ."
- Ø§ÙƒØªØ¨ Ø¥Ø¬Ø§Ø¨Ø© Ù‚ØµÙŠØ±Ø© ÙˆÙ…Ù†Ø¸Ù…Ø© Ø¨Ù†Ù‚Ø§Ø·.
- Ù„Ø§ ØªØ°ÙƒØ± Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø¯Ø§Ø®Ù„ Ø§Ù„Ù†Øµ (Ø³Ø£Ø¶ÙŠÙÙ‡Ø§ Ø£Ù†Ø§ ÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ©).

----
Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©:
{knowledge}

Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {message}

Ø§ÙƒØªØ¨ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ø¢Ù†:
""".strip()

            final_answer = ""
            for chunk in self.llm.stream([HumanMessage(content=generation_prompt)]):
                if getattr(chunk, "content", None):
                    final_answer += chunk.content
                    final_answer = TextFormatter.clean_repeated_characters(final_answer)
                    yield final_answer

            final_answer = final_answer.strip()
            final_answer += SourceDisplayManager.sources_footer_once(top_docs, source_choices)
            yield final_answer

        except Exception as e:
            traceback.print_exc()
            logger.exception("Error generating response")

            msg = str(e)
            if "No endpoints found" in msg or "404" in msg:
                yield "âš ï¸ Ø§Ù„Ù…ÙˆØ¯Ù„ ØºÙŠØ± Ù…ØªÙˆÙØ±. ØºÙŠÙ‘Ø±ÙŠ LLM_MODEL ÙÙŠ .env Ø¥Ù„Ù‰ Ù…ÙˆØ¯Ù„ Ø´ØºØ§Ù„."
                return

            if getattr(config, "DEBUG", False):
                yield f"âš ï¸ Ø®Ø·Ø£: {type(e).__name__}: {e}"
            else:
                yield "Ø¹Ø°Ø±Ù‹Ø§ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø³Ø¤Ø§Ù„Ùƒ. Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰."


# ---------------------------------------------------------------------
# UI (Gradio) - FIXED (clickable + correct messages format)
# ---------------------------------------------------------------------
def create_gradio_interface(chatbot: SFDAChatbot) -> gr.Blocks:
    css_code = """
.gradio-container { font-family: Tahoma, sans-serif; }

/* âœ… Center login WITHOUT position:fixed (so it won't block after hide) */
#login_row {
  min-height: 100vh;
  display: flex;
  align-items: center;
  justify-content: center;
  padding: 24px;
}
#login_card {
  width: min(520px, 92vw);
  padding: 22px;
  border-radius: 16px;
  border: 1px solid rgba(255,255,255,0.12);
  background: rgba(20, 24, 33, 0.88);
  box-shadow: 0 20px 60px rgba(0,0,0,0.35);
}
"""

    with gr.Blocks(css=css_code) as demo:
        # views
        with gr.Column(visible=True) as login_view:
            with gr.Row(elem_id="login_row"):
                with gr.Column(elem_id="login_card"):
                    gr.Markdown("## Login")
                    u = gr.Textbox(label="Username", placeholder="Ø§Ø¯Ø®Ù„ÙŠ Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…")
                    p = gr.Textbox(label="Password", placeholder="Ø§Ø¯Ø®Ù„ÙŠ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±", type="password")
                    login_btn = gr.Button("Login", variant="primary")
                    login_msg = gr.Markdown("")

        with gr.Column(visible=False) as app_view:
            gr.Markdown("# SANAD")
            gr.Markdown("Ø§Ø®ØªØ§Ø±ÙŠ **Ù…ØµØ¯Ø±/Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø¨Ø­Ø«** Ø«Ù… Ø§ÙƒØªØ¨ÙŠ Ø³Ø¤Ø§Ù„Ùƒ ÙˆØ§Ø¶ØºØ·ÙŠ **Ø¥Ø±Ø³Ø§Ù„**.")

            source_choices = gr.CheckboxGroup(
                choices=["Ù„ÙˆØ§Ø¦Ø­ Ø§Ù„ØªØ¬Ù…ÙŠÙ„ (PDF)", "Ù…Ø­Ø¸ÙˆØ±Ø§Øª Ø§Ù„ØªØ¬Ù…ÙŠÙ„", "Ø§Ù„Ø£Ø³Ø³ (GDP)"],
                value=["Ù„ÙˆØ§Ø¦Ø­ Ø§Ù„ØªØ¬Ù…ÙŠÙ„ (PDF)"],
                label="Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø¨Ø­Ø« (Ø§Ø®ØªÙŠØ§Ø± ÙˆØ§Ø­Ø¯ Ø£Ùˆ Ø£ÙƒØ«Ø±)",
            )

            # âœ… Gradio 6.5.1 expects messages format: list[dict(role,content)]
            chat = gr.Chatbot(label="Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©", height=520)
            state = gr.State([])  # list[dict]

            with gr.Row():
                msg = gr.Textbox(placeholder="Ø§ÙƒØªØ¨ÙŠ Ø³Ø¤Ø§Ù„Ùƒ...", show_label=False, scale=8)
                send = gr.Button("Ø¥Ø±Ø³Ø§Ù„", variant="primary", scale=2)

            clear = gr.Button("Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©")

            def init_chat():
                history = [{
                    "role": "assistant",
                    "content": (
                        "ğŸ‘‹ **Ø£Ù…Ø«Ù„Ø© Ø¬Ø§Ù‡Ø²Ø© (Ø§Ù†Ø³Ø®ÙŠ/Ø§Ù„ØµÙ‚ÙŠ Ø³Ø¤Ø§Ù„Ø§Ù‹ Ø£Ùˆ Ø§ÙƒØªØ¨ÙŠÙ‡):**\n\n"
                        "â€¢ Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ø±Ø§Ø¨Ø¹Ø©ØŸ\n"
                        "â€¢ Ø§Ø°ÙƒØ± Ø§Ù„ØªØ²Ø§Ù…Ø§Øª Ø§Ù„Ù…ÙØ¯Ø±Ø¬ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…\n"
                        "â€¢ Ù‡Ù„ Mercury Ù…Ø­Ø¸ÙˆØ± ÙÙŠ Ø§Ù„ØªØ¬Ù…ÙŠÙ„ØŸ\n"
                        "â€¢ Ø§Ø°ÙƒØ± Ù„ÙŠ 5 Ù…ÙˆØ§Ø¯ Ù…Ø­Ø¸ÙˆØ±Ø© ØªØ¨Ø¯Ø£ Ø¨Ø­Ø±Ù M\n"
                        "â€¢ Ù…Ø§ Ù‡ÙŠ Ù…ØªØ·Ù„Ø¨Ø§Øª Ø¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø© ÙˆØ§Ù„Ø±Ø·ÙˆØ¨Ø© ÙÙŠ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹Ø§ØªØŸ\n"
                    )
                }]
                return history, history

            demo.load(fn=init_chat, inputs=None, outputs=[chat, state])

            def add_user(user_message, history):
                user_message = (user_message or "").strip()
                history = history or []
                if not user_message:
                    return gr.update(value=""), history, history

                history.append({"role": "user", "content": user_message})
                history.append({"role": "assistant", "content": ""})
                return gr.update(value=""), history, history

            def stream_bot(history, choices):
                history = history or []
                if len(history) < 2:
                    yield history, history
                    return

                user_msg = history[-2]["content"]
                for chunk in chatbot.stream_response_core(user_msg, choices):
                    history[-1]["content"] = chunk
                    yield history, history

            send.click(fn=add_user, inputs=[msg, state], outputs=[msg, state, chat]).then(
                fn=stream_bot, inputs=[state, source_choices], outputs=[chat, state]
            )
            msg.submit(fn=add_user, inputs=[msg, state], outputs=[msg, state, chat]).then(
                fn=stream_bot, inputs=[state, source_choices], outputs=[chat, state]
            )

            def clear_all():
                return [], []

            clear.click(fn=clear_all, inputs=None, outputs=[chat, state])

        # ---------------- LOGIN LOGIC ----------------
        def do_login(username, password):
            username = (username or "").strip()
            password = (password or "").strip()

            if username == str(config.GRADIO_USERNAME) and password == str(config.GRADIO_PASSWORD):
                # hide login, show app, clear msg + clear fields
                return (
                    gr.update(visible=False),
                    gr.update(visible=True),
                    gr.update(value=""),
                    gr.update(value=""),
                    gr.update(value=""),
                )

            return (
                gr.update(visible=True),
                gr.update(visible=False),
                gr.update(value="âŒ Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ØµØ­ÙŠØ­Ø©"),
                gr.update(value=""),
                gr.update(value=""),
            )

        login_btn.click(
            fn=do_login,
            inputs=[u, p],
            outputs=[login_view, app_view, login_msg, u, p],
        )

    return demo


def main():
    bot = SFDAChatbot()
    demo = create_gradio_interface(bot)
    demo.queue().launch(
        share=True,
        show_error=True,
        debug=True,
    )


if __name__ == "__main__":
    main()
