"""
Improved Gradio Application for SFDA Cosmetics Chatbot.
Compatible with new Project Structure (Best Practices).
No Authentication Required.
Fixed: Gradio 'messages' type error.
"""

import os
import re
import sys
import traceback
from typing import List, Optional, Iterator

import gradio as gr
from langchain_openai import ChatOpenAI
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain_core.documents import Document
from langchain_core.messages import HumanMessage

from src.utils.logger import logger
from src import config

# ---------------------------------------------------------------------
# Helpers (Ù†ÙØ³ Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©)
# ---------------------------------------------------------------------
class ArabicArticleParser:
    AR_WORD_TO_NUM = {
        "Ø§Ù„Ø£ÙˆÙ„Ù‰": "1", "Ø§Ù„Ø§ÙˆÙ„Ù‰": "1", "Ø§Ù„Ø«Ø§Ù†ÙŠØ©": "2", "Ø§Ù„Ø«Ø§Ù„Ø«Ø©": "3", "Ø§Ù„Ø±Ø§Ø¨Ø¹Ø©": "4", 
        "Ø§Ù„Ø®Ø§Ù…Ø³Ø©": "5", "Ø§Ù„Ø³Ø§Ø¯Ø³Ø©": "6", "Ø§Ù„Ø³Ø§Ø¨Ø¹Ø©": "7", "Ø§Ù„Ø«Ø§Ù…Ù†Ø©": "8", "Ø§Ù„ØªØ§Ø³Ø¹Ø©": "9", 
        "Ø§Ù„Ø¹Ø§Ø´Ø±Ø©": "10", "Ø§Ù„Ø­Ø§Ø¯ÙŠØ© Ø¹Ø´Ø±": "11", "Ø§Ù„Ø­Ø§Ø¯ÙŠØ© Ø¹Ø´Ø±Ø©": "11", "Ø§Ù„Ø«Ø§Ù†ÙŠØ© Ø¹Ø´Ø±": "12", 
        "Ø§Ù„Ø«Ø§Ù†ÙŠØ© Ø¹Ø´Ø±Ø©": "12", "Ø§Ù„Ø«Ø§Ù„Ø«Ø© Ø¹Ø´Ø±": "13", "Ø§Ù„Ø«Ø§Ù„Ø«Ø© Ø¹Ø´Ø±Ø©": "13", "Ø§Ù„Ø±Ø§Ø¨Ø¹Ø© Ø¹Ø´Ø±": "14", 
        "Ø§Ù„Ø±Ø§Ø¨Ø¹Ø© Ø¹Ø´Ø±Ø©": "14", "Ø§Ù„Ø®Ø§Ù…Ø³Ø© Ø¹Ø´Ø±": "15", "Ø§Ù„Ø®Ø§Ù…Ø³Ø© Ø¹Ø´Ø±Ø©": "15", "Ø§Ù„Ø³Ø§Ø¯Ø³Ø© Ø¹Ø´Ø±": "16", 
        "Ø§Ù„Ø³Ø§Ø¯Ø³Ø© Ø¹Ø´Ø±Ø©": "16", "Ø§Ù„Ø³Ø§Ø¨Ø¹Ø© Ø¹Ø´Ø±": "17", "Ø§Ù„Ø³Ø§Ø¨Ø¹Ø© Ø¹Ø´Ø±Ø©": "17", "Ø§Ù„Ø«Ø§Ù…Ù†Ø© Ø¹Ø´Ø±": "18", 
        "Ø§Ù„Ø«Ø§Ù…Ù†Ø© Ø¹Ø´Ø±Ø©": "18", "Ø§Ù„ØªØ§Ø³Ø¹Ø© Ø¹Ø´Ø±": "19", "Ø§Ù„ØªØ§Ø³Ø¹Ø© Ø¹Ø´Ø±Ø©": "19", "Ø§Ù„Ø¹Ø´Ø±ÙˆÙ†": "20", 
        "Ø§Ù„Ø­Ø§Ø¯ÙŠØ© ÙˆØ§Ù„Ø¹Ø´Ø±ÙˆÙ†": "21", "Ø§Ù„Ø«Ø§Ù†ÙŠØ© ÙˆØ§Ù„Ø¹Ø´Ø±ÙˆÙ†": "22", "Ø§Ù„Ø«Ø§Ù„Ø«Ø© ÙˆØ§Ù„Ø¹Ø´Ø±ÙˆÙ†": "23", 
        "Ø§Ù„Ø±Ø§Ø¨Ø¹Ø© ÙˆØ§Ù„Ø¹Ø´Ø±ÙˆÙ†": "24", "Ø§Ù„Ø®Ø§Ù…Ø³Ø© ÙˆØ§Ù„Ø¹Ø´Ø±ÙˆÙ†": "25", "Ø§Ù„Ø³Ø§Ø¯Ø³Ø© ÙˆØ§Ù„Ø¹Ø´Ø±ÙˆÙ†": "26", 
        "Ø§Ù„Ø³Ø§Ø¨Ø¹Ø© ÙˆØ§Ù„Ø¹Ø´Ø±ÙˆÙ†": "27", "Ø§Ù„Ø«Ø§Ù…Ù†Ø© ÙˆØ§Ù„Ø¹Ø´Ø±ÙˆÙ†": "28", "Ø§Ù„ØªØ§Ø³Ø¹Ø© ÙˆØ§Ù„Ø¹Ø´Ø±ÙˆÙ†": "29", "Ø§Ù„Ø«Ù„Ø§Ø«ÙˆÙ†": "30",
    }
    @classmethod
    def normalize_article_to_num(cls, article_value: str) -> Optional[str]:
        if article_value is None: return None
        s = str(article_value).strip().replace("Ù€", "")
        s = re.sub(r"\s{2,}", " ", s)
        s = re.sub(r"^\s*Ø§Ù„Ù…Ø§Ø¯Ø©\s+", "", s).strip()
        if re.fullmatch(r"\d+", s): return s
        if s in cls.AR_WORD_TO_NUM: return cls.AR_WORD_TO_NUM[s]
        words = s.split()
        for n in (4, 3, 2, 1):
            if len(words) >= n:
                cand = " ".join(words[:n])
                if cand in cls.AR_WORD_TO_NUM: return cls.AR_WORD_TO_NUM[cand]
        return None
    @classmethod
    def extract_article_number(cls, text: str) -> Optional[str]:
        text = text or ""
        m = re.search(r"Ø§Ù„Ù…Ø§Ø¯Ø©\s+(\d+)", text)
        if m: return m.group(1)
        m = re.search(r"Ø§Ù„Ù…Ø§Ø¯Ø©\s+([^\nØŒ,.ØŸ!]+)", text)
        if not m: return None
        phrase = re.sub(r"\s{2,}", " ", m.group(1).replace("Ù€", "")).strip()
        phrase = re.sub(r"^\s*Ø§Ù„Ù…Ø§Ø¯Ø©\s+", "", phrase).strip()
        if phrase in cls.AR_WORD_TO_NUM: return cls.AR_WORD_TO_NUM[phrase]
        words = phrase.split()
        for n in (4, 3, 2, 1):
            if len(words) >= n:
                cand = " ".join(words[:n])
                if cand in cls.AR_WORD_TO_NUM: return cls.AR_WORD_TO_NUM[cand]
        return None

class TextFormatter:
    @staticmethod
    def clean_repeated_characters(text: str) -> str:
        return re.sub(r"(.)\1{2,}", r"\1", text or "")
    @staticmethod
    def pretty_arabic_text(text: str) -> str:
        if not text: return ""
        t = text.replace("\r\n", "\n").replace("\r", "\n").replace("Ù€", "")
        t = re.sub(r"[ \t]+", " ", t)
        t = re.sub(r"\n{3,}", "\n\n", t)
        return t.strip()

class SourceDisplayManager:
    @staticmethod
    def display_source_name_from_doc(doc: Document) -> str:
        cat = (doc.metadata.get("category") or "").lower().strip()
        if cat == "banned": return "Ù…Ø­Ø¸ÙˆØ±Ø§Øª Ø§Ù„ØªØ¬Ù…ÙŠÙ„"
        if cat == "regulation": return "Ù„ÙˆØ§Ø¦Ø­ Ø§Ù„ØªØ¬Ù…ÙŠÙ„"
        if cat in ("gdp", "guidelines"): return "Ø§Ù„Ø£Ø³Ø³ (Ø§Ù„ØªÙˆØ²ÙŠØ¹ ÙˆØ§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø¬ÙŠØ¯Ø©)"
        raw = doc.metadata.get("source", doc.metadata.get("source_file", "N/A"))
        return os.path.basename(raw or "N/A").strip() or "Ù…ØµØ§Ø¯Ø± Ø¥Ø¶Ø§ÙÙŠØ©"
    @staticmethod
    def sources_footer_once(docs: List[Document], chosen_sources_ui: List[str]) -> str:
        if chosen_sources_ui and set(chosen_sources_ui) == {"Ù…Ø­Ø¸ÙˆØ±Ø§Øª Ø§Ù„ØªØ¬Ù…ÙŠÙ„"}:
            return "\n\n**Ø§Ù„Ù…ØµØ¯Ø±:** Ù…Ø­Ø¸ÙˆØ±Ø§Øª Ø§Ù„ØªØ¬Ù…ÙŠÙ„"
        seen = set()
        sources = []
        for d in docs:
            name = SourceDisplayManager.display_source_name_from_doc(d)
            if name and name not in seen:
                seen.add(name)
                sources.append(name)
        return "\n\n**Ø§Ù„Ù…ØµØ¯Ø±:** " + ("ØŒ ".join(sources) if sources else "N/A")

# ---------------------------------------------------------------------
# Main Chatbot Logic
# ---------------------------------------------------------------------
class SFDAChatbot:
    def __init__(self):
        logger.info("Initializing SFDA Chatbot...")
        if not getattr(config, "OPENROUTER_API_KEY", None) and not getattr(config, "OPENAI_API_KEY", None):
            raise ValueError("API Keys missing in .env")

        logger.info(f"Loading embedding model: {config.EMBEDDING_MODEL}")
        self.embeddings_model = HuggingFaceEmbeddings(
            model_name=config.EMBEDDING_MODEL,
            model_kwargs={"device": config.EMBEDDING_DEVICE},
        )

        logger.info("Initializing LLM...")
        self.llm = ChatOpenAI(
            model=config.LLM_MODEL,
            temperature=config.LLM_TEMPERATURE,
            api_key=(config.OPENROUTER_API_KEY or config.OPENAI_API_KEY),
            base_url=config.LLM_BASE_URL,
            max_tokens=config.LLM_MAX_TOKENS,
        )

        db_path = str(config.CHROMA_PATH)
        logger.info(f"Connecting to Vector Store at: {db_path}")
        
        self.vector_store = Chroma(
            collection_name=config.COLLECTION_NAME,
            embedding_function=self.embeddings_model,
            persist_directory=db_path,
        )
        try:
            if hasattr(self.vector_store, '_collection'):
                count = self.vector_store._collection.count()
                logger.info(f"Vector store loaded. Document count: {count}")
        except Exception as e:
            logger.warning(f"Could not get vector store count: {e}")

        logger.info("âœ… Chatbot initialized successfully")

    def get_article_doc(self, article_num: str) -> Optional[Document]:
        target = str(article_num).strip()
        try:
            docs = self.vector_store.similarity_search(
                query=f"Ø§Ù„Ù…Ø§Ø¯Ø© {target}",
                k=3,
                filter={"$and": [{"article": target}, {"category": "regulation"}]},
            )
            if docs: return docs[0]
        except Exception as e:
            logger.debug(f"Regulation search failed: {e}")
        try:
            docs = self.vector_store.similarity_search(
                query=f"Ø§Ù„Ù…Ø§Ø¯Ø© {target}",
                k=3,
                filter={"article": target},
            )
            if docs: return docs[0]
        except Exception as e:
            logger.debug(f"General article search failed: {e}")
        return None

    def build_retriever(self, ui_choices: List[str]):
        if not ui_choices:
            return self.vector_store.as_retriever(search_kwargs={"k": config.RETRIEVAL_K})
        selected_categories = []
        for ch in ui_choices:
            if "Ù„ÙˆØ§Ø¦Ø­" in ch: selected_categories.append("regulation")
            elif "Ù…Ø­Ø¸ÙˆØ±Ø§Øª" in ch: selected_categories.append("banned")
            elif "Ø§Ù„Ø£Ø³Ø³" in ch: selected_categories.append("gdp")
        if not selected_categories or len(selected_categories) >= 3:
            return self.vector_store.as_retriever(search_kwargs={"k": config.RETRIEVAL_K})
        if len(selected_categories) == 1:
            return self.vector_store.as_retriever(
                search_kwargs={"k": config.RETRIEVAL_K, "filter": {"category": selected_categories[0]}}
            )
        or_filter = {"$or": [{"category": c} for c in selected_categories]}
        return self.vector_store.as_retriever(search_kwargs={"k": config.RETRIEVAL_K, "filter": or_filter})

    @staticmethod
    def build_knowledge(docs: List[Document]) -> str:
        parts = []
        for d in docs:
            src = SourceDisplayManager.display_source_name_from_doc(d)
            snippet = TextFormatter.pretty_arabic_text(d.page_content)[:1400]
            parts.append(f"[{src}]\n{snippet}")
        return "\n\n".join(parts)

    def stream_response_core(self, message: str, source_choices: List[str]) -> Iterator[str]:
        message = (message or "").strip()
        if not message:
            yield "Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ."
            return

        try:
            art_num = ArabicArticleParser.extract_article_number(message)
            if art_num:
                if source_choices and all("Ù…Ø­Ø¸ÙˆØ±Ø§Øª" in s for s in source_choices):
                    yield "Ø¹Ø°Ø±Ù‹Ø§ØŒ Ø³Ø¤Ø§Ù„ **Ø§Ù„Ù…Ø§Ø¯Ø©** ÙŠÙƒÙˆÙ† Ø¶Ù…Ù† **Ù„ÙˆØ§Ø¦Ø­ Ø§Ù„ØªØ¬Ù…ÙŠÙ„**. Ø§Ù„Ø±Ø¬Ø§Ø¡ ØªØºÙŠÙŠØ± Ø§Ù„Ù…ØµØ¯Ø±."
                    return
                doc = self.get_article_doc(art_num)
                if doc:
                    answer = TextFormatter.pretty_arabic_text(doc.page_content)
                    answer += SourceDisplayManager.sources_footer_once([doc], source_choices)
                    yield answer
                    return
                else:
                    logger.info(f"Article {art_num} not found directly, switching to semantic search.")

            retriever = self.build_retriever(source_choices)
            retrieved_docs = retriever.invoke(message) 

            if not retrieved_docs:
                yield "Ù„Ù… Ø£Ø¬Ø¯ Ù†ØµÙ‹Ø§ ØµØ±ÙŠØ­Ù‹Ø§ ÙÙŠ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…ØªØ§Ø­Ø© ÙŠØ¬ÙŠØ¨ Ø¹Ù† Ø°Ù„Ùƒ."
                return

            top_docs = retrieved_docs[:3]
            knowledge = self.build_knowledge(top_docs)

            generation_prompt = f"""
ROLE: Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù„Ù‡ÙŠØ¦Ø© Ø§Ù„ØºØ°Ø§Ø¡ ÙˆØ§Ù„Ø¯ÙˆØ§Ø¡.
CONTEXT:
{knowledge}

USER QUESTION: {message}

INSTRUCTIONS:
- Ø£Ø¬Ø¨ Ø¨Ø¯Ù‚Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø±ÙÙ‚Ø© ÙÙ‚Ø·.
- Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù‚Ù„ "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙÙŠ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…ØªØ§Ø­Ø©".
- ÙƒÙ† Ù…Ø®ØªØµØ±Ø§Ù‹ ÙˆÙ…ÙÙŠØ¯Ø§Ù‹.
""".strip()

            final_answer = ""
            for chunk in self.llm.stream([HumanMessage(content=generation_prompt)]):
                if chunk.content:
                    final_answer += chunk.content
                    yield final_answer

            yield final_answer + SourceDisplayManager.sources_footer_once(top_docs, source_choices)

        except Exception as e:
            logger.error(f"Error generating response: {e}", exc_info=True)
            yield "Ø¹Ø°Ø±Ù‹Ø§ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ØªÙ‚Ù†ÙŠ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©."

# ---------------------------------------------------------------------
# UI (Gradio)
# ---------------------------------------------------------------------
def create_gradio_interface(chatbot: SFDAChatbot) -> gr.Blocks:
    css_code = """
    .gradio-container { font-family: 'Segoe UI', Tahoma, sans-serif; }
    """

    with gr.Blocks(css=css_code, title="SANAD Chatbot") as demo:
        gr.Markdown("## ğŸ‡¸ğŸ‡¦ SANAD - Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„ÙˆØ§Ø¦Ø­ Ø§Ù„ØªØ¬Ù…ÙŠÙ„")
        
        with gr.Row():
            source_choices = gr.CheckboxGroup(
                choices=["Ù„ÙˆØ§Ø¦Ø­ Ø§Ù„ØªØ¬Ù…ÙŠÙ„ (PDF)", "Ù…Ø­Ø¸ÙˆØ±Ø§Øª Ø§Ù„ØªØ¬Ù…ÙŠÙ„", "Ø§Ù„Ø£Ø³Ø³ (GDP)"],
                value=["Ù„ÙˆØ§Ø¦Ø­ Ø§Ù„ØªØ¬Ù…ÙŠÙ„ (PDF)"],
                label="ğŸ” Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø¨Ø­Ø«",
            )
        
        # --- Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¬ÙˆÙ‡Ø±ÙŠ Ù‡Ù†Ø§: type="messages" ---
        chatbot_ui = gr.Chatbot(label="Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©", height=550, type="messages")
        
        with gr.Row():
            msg = gr.Textbox(placeholder="Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§...", scale=4)
            send = gr.Button("Ø¥Ø±Ø³Ø§Ù„", variant="primary", scale=1)
        
        clear = gr.Button("Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©")

        # --- Functions ---
        def user_msg_fn(user_message, history):
            if not user_message: return history, ""
            history.append({"role": "user", "content": user_message})
            return history, ""

        def bot_msg_fn(history, choices):
            if not history: return history
            last_user_msg = history[-1]["content"]
            
            history.append({"role": "assistant", "content": ""})
            
            for chunk in chatbot.stream_response_core(last_user_msg, choices):
                history[-1]["content"] = chunk
                yield history

        # --- Event Listeners ---
        msg.submit(user_msg_fn, [msg, chatbot_ui], [chatbot_ui, msg]).then(
            bot_msg_fn, [chatbot_ui, source_choices], chatbot_ui
        )
        send.click(user_msg_fn, [msg, chatbot_ui], [chatbot_ui, msg]).then(
            bot_msg_fn, [chatbot_ui, source_choices], chatbot_ui
        )
        clear.click(lambda: [], None, chatbot_ui)

    return demo

def main():
    try:
        bot = SFDAChatbot()
        demo = create_gradio_interface(bot)
        demo.queue().launch(share=False)
    except Exception as e:
        logger.critical(f"Failed to launch UI: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()