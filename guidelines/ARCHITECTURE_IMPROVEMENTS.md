# ØªØ­Ø³ÙŠÙ†Ø§Øª Architecture Ø¶Ù…Ù† Best Practices
**Ø§Ù„ØªØ§Ø±ÙŠØ®:** 2026-01-31
**Ø§Ù„Ù…Ø´Ø±ÙˆØ¹:** SFDA Legal Assistant

---

## ğŸ“‹ ØªØ­Ù„ÙŠÙ„ Ù…Ù‚ØªØ±Ø­Ø§ØªÙƒ Ø§Ù„Ø­Ø§Ù„ÙŠØ©

### âœ… Ù†Ù‚Ø§Ø· Ù‚ÙˆØ© ÙÙŠ Ù…Ù‚ØªØ±Ø­Ø§ØªÙƒ:

1. **Query Classification** - Ù…Ù…ØªØ§Ø²!
2. **Cache Layer** - Ø¶Ø±ÙˆØ±ÙŠ Ø¬Ø¯Ø§Ù‹!
3. **Source Tagging** - Ù…Ø·Ù„ÙˆØ¨ ÙÙŠ MVP!
4. **Checkboxes Ù„Ù„Ù…ØµØ§Ø¯Ø±** - UX Ù…Ù…ØªØ§Ø²!

---

## ğŸš€ ØªØ­Ø³ÙŠÙ†Ø§Øª Best Practices Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ©

### 1. **Structured Logging & Monitoring**

```python
# âœ… Best Practice: Structured logging
import logging
import json
from datetime import datetime

class StructuredLogger:
    def __init__(self, name="sfda_assistant"):
        self.logger = logging.getLogger(name)

    def log_query(self, query, query_type, response_time, cache_hit=False):
        log_data = {
            "timestamp": datetime.utcnow().isoformat(),
            "query": query[:100],  # Ø£ÙˆÙ„ 100 Ø­Ø±Ù ÙÙ‚Ø·
            "query_type": query_type,
            "response_time_ms": response_time,
            "cache_hit": cache_hit,
            "success": True
        }
        self.logger.info(json.dumps(log_data, ensure_ascii=False))

    def log_error(self, query, error, stack_trace):
        log_data = {
            "timestamp": datetime.utcnow().isoformat(),
            "query": query[:100],
            "error": str(error),
            "stack_trace": stack_trace,
            "success": False
        }
        self.logger.error(json.dumps(log_data, ensure_ascii=False))

# Ø§Ø³ØªØ®Ø¯Ø§Ù…:
logger = StructuredLogger()
logger.log_query("Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ø±Ø§Ø¨Ø¹Ø©ØŸ", "rag", 234, cache_hit=True)
```

**Ø§Ù„ÙØ§Ø¦Ø¯Ø©:**
- ØªØªØ¨Ø¹ Ø§Ù„Ø£Ø¯Ø§Ø¡
- ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
- Debug Ø³Ø±ÙŠØ¹
- Analytics Ù„Ø§Ø­Ù‚Ø§Ù‹

---

### 2. **Cache Expiration & Invalidation Strategy**

```python
# âœ… Best Practice: Smart caching Ù…Ø¹ expiration
from datetime import datetime, timedelta
import hashlib

class SmartCache:
    def __init__(self, ttl_hours=24):
        self.cache = {}
        self.ttl = timedelta(hours=ttl_hours)

    def _hash_query(self, query, filters):
        """Create unique hash Ù„Ù„Ù€ query + filters"""
        key = f"{query}:{json.dumps(filters, sort_keys=True)}"
        return hashlib.md5(key.encode()).hexdigest()

    def get(self, query, filters=None):
        filters = filters or {}
        key = self._hash_query(query, filters)

        if key in self.cache:
            entry = self.cache[key]
            # âœ… ØªØ­Ù‚Ù‚ Ù…Ù† expiration
            if datetime.now() - entry["timestamp"] < self.ttl:
                return entry["response"]
            else:
                # âœ… Ø§Ù…Ø³Ø­ Ø§Ù„Ù€ expired
                del self.cache[key]

        return None

    def set(self, query, response, filters=None):
        filters = filters or {}
        key = self._hash_query(query, filters)
        self.cache[key] = {
            "response": response,
            "timestamp": datetime.now(),
            "hit_count": 0
        }

    def invalidate_pattern(self, pattern):
        """Ø§Ù…Ø³Ø­ ÙƒÙ„ Ø§Ù„Ù€ cache Ø§Ù„Ù…ØªØ¹Ù„Ù‚ Ø¨Ù…ÙˆØ¶ÙˆØ¹ Ù…Ø¹ÙŠÙ†"""
        keys_to_delete = [k for k in self.cache.keys() if pattern in k]
        for k in keys_to_delete:
            del self.cache[k]

    def get_stats(self):
        """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù€ cache"""
        return {
            "total_entries": len(self.cache),
            "memory_usage_mb": len(str(self.cache)) / (1024 * 1024),
            "oldest_entry": min((v["timestamp"] for v in self.cache.values()), default=None)
        }

# Ø§Ø³ØªØ®Ø¯Ø§Ù…:
cache = SmartCache(ttl_hours=24)

# Ø­ÙØ¸
cache.set("Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù…Ø§Ø¯Ø© 4ØŸ", "Ù†Øµ Ø§Ù„Ù…Ø§Ø¯Ø©...", {"source": "regulations"})

# Ø§Ø³ØªØ±Ø¬Ø§Ø¹
result = cache.get("Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù…Ø§Ø¯Ø© 4ØŸ", {"source": "regulations"})

# invalidate Ø¹Ù†Ø¯ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
cache.invalidate_pattern("Ø§Ù„Ù…Ø§Ø¯Ø© 4")
```

---

### 3. **Rate Limiting & Cost Control**

```python
# âœ… Best Practice: Ù…Ù†Ø¹ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙØ±Ø· Ù„Ù„Ù€ API
from collections import defaultdict
from datetime import datetime, timedelta

class RateLimiter:
    def __init__(self, max_requests_per_minute=10, max_cost_per_hour=1.0):
        self.requests = defaultdict(list)  # user_id -> [timestamps]
        self.costs = defaultdict(float)    # user_id -> total_cost
        self.max_rpm = max_requests_per_minute
        self.max_cost = max_cost_per_hour

    def check_rate_limit(self, user_id="default"):
        now = datetime.now()
        minute_ago = now - timedelta(minutes=1)

        # Ø§Ù…Ø³Ø­ Ø§Ù„Ù€ old requests
        self.requests[user_id] = [
            ts for ts in self.requests[user_id]
            if ts > minute_ago
        ]

        # ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø­Ø¯
        if len(self.requests[user_id]) >= self.max_rpm:
            return False, f"ØªØ¬Ø§ÙˆØ²Øª Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­ ({self.max_rpm} Ø·Ù„Ø¨/Ø¯Ù‚ÙŠÙ‚Ø©)"

        return True, None

    def record_request(self, user_id="default", cost=0.0):
        self.requests[user_id].append(datetime.now())
        self.costs[user_id] += cost

    def check_cost_limit(self, user_id="default"):
        if self.costs[user_id] >= self.max_cost:
            return False, f"ØªØ¬Ø§ÙˆØ²Øª Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ø§Ù„ØªÙƒÙ„ÙØ© ({self.max_cost}$/Ø³Ø§Ø¹Ø©)"
        return True, None

# Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙŠ Gradio:
rate_limiter = RateLimiter(max_requests_per_minute=20)

def handle_query(query, user_session):
    # âœ… ØªØ­Ù‚Ù‚ Ù…Ù† rate limit
    allowed, error = rate_limiter.check_rate_limit(user_session)
    if not allowed:
        return f"âš ï¸ {error}. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ù‚Ù„ÙŠÙ„Ø§Ù‹."

    # Ù…Ø¹Ø§Ù„Ø¬Ø©...
    response = process_query(query)

    # âœ… Ø³Ø¬Ù„ Ø§Ù„ØªÙƒÙ„ÙØ©
    rate_limiter.record_request(user_session, cost=0.001)

    return response
```

---

### 4. **Query Validation & Sanitization**

```python
# âœ… Best Practice: ØªÙ†Ø¸ÙŠÙ ÙˆÙØ­Øµ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª
import re

class QueryValidator:
    # âœ… Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ØºÙŠØ± Ø§Ù„Ù…Ø³Ù…ÙˆØ­Ø©
    FORBIDDEN_PATTERNS = [
        r"ÙƒÙŠÙ Ø£ØªÙ‡Ø±Ø¨ Ù…Ù†",
        r"ÙƒÙŠÙ Ø£Ø®Ø§Ù„Ù",
        r"Ø·Ø±ÙŠÙ‚Ø© ØºØ´",
        r"ignore (previous|above) instructions",  # Prompt injection
        r"<script",  # XSS attempt
    ]

    # âœ… Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ø·ÙˆÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„
    MAX_LENGTH = 500

    @staticmethod
    def is_valid(query):
        """ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø³Ø¤Ø§Ù„"""
        if not query or not query.strip():
            return False, "Ø§Ù„Ø³Ø¤Ø§Ù„ ÙØ§Ø±Øº"

        if len(query) > QueryValidator.MAX_LENGTH:
            return False, f"Ø§Ù„Ø³Ø¤Ø§Ù„ Ø·ÙˆÙŠÙ„ Ø¬Ø¯Ø§Ù‹ (Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ {QueryValidator.MAX_LENGTH} Ø­Ø±Ù)"

        # âœ… ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ø­Ø§ÙˆÙ„Ø§Øª prompt injection
        for pattern in QueryValidator.FORBIDDEN_PATTERNS:
            if re.search(pattern, query, re.IGNORECASE):
                return False, "Ø§Ù„Ø³Ø¤Ø§Ù„ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ ØºÙŠØ± Ù…Ø³Ù…ÙˆØ­"

        return True, None

    @staticmethod
    def sanitize(query):
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø³Ø¤Ø§Ù„"""
        # Ø¥Ø²Ø§Ù„Ø© HTML tags
        query = re.sub(r'<[^>]+>', '', query)
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
        query = re.sub(r'\s+', ' ', query).strip()
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ø®Ø·Ø±Ø©
        query = query.replace('\x00', '')
        return query

# Ø§Ø³ØªØ®Ø¯Ø§Ù…:
validator = QueryValidator()

def process_user_query(raw_query):
    # âœ… ØªÙ†Ø¸ÙŠÙ
    clean_query = validator.sanitize(raw_query)

    # âœ… ÙØ­Øµ
    is_valid, error = validator.is_valid(clean_query)
    if not is_valid:
        return f"âš ï¸ Ø®Ø·Ø£: {error}"

    # Ù…Ø¹Ø§Ù„Ø¬Ø©...
    return handle_query(clean_query)
```

---

### 5. **Graceful Degradation & Fallbacks**

```python
# âœ… Best Practice: Ø®Ø·Ø© Ø¨Ø¯ÙŠÙ„Ø© Ø¹Ù†Ø¯ ÙØ´Ù„ Ø£ÙŠ component
class ResilientQueryHandler:
    def __init__(self, primary_llm, fallback_llm=None):
        self.primary = primary_llm
        self.fallback = fallback_llm
        self.cache = SmartCache()

    def handle(self, query):
        # âœ… Ø§Ù„Ù…Ø³ØªÙˆÙ‰ 1: Cache
        cached = self.cache.get(query)
        if cached:
            return cached, "cache"

        # âœ… Ø§Ù„Ù…Ø³ØªÙˆÙ‰ 2: Primary LLM
        try:
            response = self.primary.invoke(query)
            self.cache.set(query, response)
            return response, "primary_llm"
        except Exception as e:
            logger.log_error(query, e, traceback.format_exc())

            # âœ… Ø§Ù„Ù…Ø³ØªÙˆÙ‰ 3: Fallback LLM
            if self.fallback:
                try:
                    response = self.fallback.invoke(query)
                    self.cache.set(query, response)
                    return response, "fallback_llm"
                except Exception as e2:
                    logger.log_error(query, e2, traceback.format_exc())

            # âœ… Ø§Ù„Ù…Ø³ØªÙˆÙ‰ 4: Static response
            return self._get_error_message(), "error"

    def _get_error_message(self):
        return """
        âš ï¸ Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ù…Ø¤Ù‚Øª ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù….

        ÙŠÙ…ÙƒÙ†Ùƒ:
        - Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø¹Ø¯ Ù‚Ù„ÙŠÙ„
        - Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ
        - Ø²ÙŠØ§Ø±Ø© Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø±Ø³Ù…ÙŠ: https://www.sfda.gov.sa
        """
```

---

### 6. **Performance Monitoring Dashboard**

```python
# âœ… Best Practice: Dashboard Ø¨Ø³ÙŠØ· Ù„Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©
import gradio as gr
from datetime import datetime

class PerformanceMonitor:
    def __init__(self):
        self.metrics = {
            "total_queries": 0,
            "cache_hits": 0,
            "avg_response_time": 0,
            "errors": 0,
            "last_update": datetime.now()
        }

    def record(self, response_time, cache_hit, error=False):
        self.metrics["total_queries"] += 1
        if cache_hit:
            self.metrics["cache_hits"] += 1
        if error:
            self.metrics["errors"] += 1

        # Update avg response time
        n = self.metrics["total_queries"]
        current_avg = self.metrics["avg_response_time"]
        self.metrics["avg_response_time"] = (
            (current_avg * (n - 1) + response_time) / n
        )
        self.metrics["last_update"] = datetime.now()

    def get_dashboard_html(self):
        cache_rate = (
            self.metrics["cache_hits"] / self.metrics["total_queries"] * 100
            if self.metrics["total_queries"] > 0 else 0
        )
        error_rate = (
            self.metrics["errors"] / self.metrics["total_queries"] * 100
            if self.metrics["total_queries"] > 0 else 0
        )

        return f"""
        <div style="padding: 20px; background: #f5f5f5; border-radius: 8px;">
            <h3>ğŸ“Š Performance Metrics</h3>
            <ul>
                <li>Total Queries: {self.metrics["total_queries"]}</li>
                <li>Cache Hit Rate: {cache_rate:.1f}%</li>
                <li>Avg Response Time: {self.metrics["avg_response_time"]:.0f}ms</li>
                <li>Error Rate: {error_rate:.1f}%</li>
                <li>Last Update: {self.metrics["last_update"].strftime('%Y-%m-%d %H:%M:%S')}</li>
            </ul>
        </div>
        """

# Ø¥Ø¶Ø§ÙØ© ÙÙŠ Gradio:
monitor = PerformanceMonitor()

with gr.Blocks() as demo:
    # ... UI Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ...

    # âœ… Ø¥Ø¶Ø§ÙØ© admin tab
    with gr.Tab("Admin Dashboard"):
        metrics_display = gr.HTML(monitor.get_dashboard_html())
        refresh_btn = gr.Button("Refresh Metrics")
        refresh_btn.click(
            lambda: monitor.get_dashboard_html(),
            outputs=metrics_display
        )
```

---

### 7. **Database Connection Pooling**

```python
# âœ… Best Practice: Ø¥Ø¹Ø§Ø¯Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù€ connections
from contextlib import contextmanager

class ChromaDBPool:
    """Connection pool Ù„Ù„Ù€ ChromaDB"""
    def __init__(self, chroma_path, collection_name, embeddings):
        self._path = chroma_path
        self._collection = collection_name
        self._embeddings = embeddings
        self._connection = None

    @property
    def connection(self):
        """Lazy loading - Ø§ØªØµØ§Ù„ ÙˆØ§Ø­Ø¯ ÙÙ‚Ø·"""
        if self._connection is None:
            self._connection = Chroma(
                collection_name=self._collection,
                embedding_function=self._embeddings,
                persist_directory=self._path,
            )
        return self._connection

    def health_check(self):
        """ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø§ØªØµØ§Ù„"""
        try:
            count = self.connection._collection.count()
            return True, f"Connected. {count} documents."
        except Exception as e:
            return False, f"Connection error: {e}"

# Ø§Ø³ØªØ®Ø¯Ø§Ù…:
# âœ… Ø§ØªØµØ§Ù„ ÙˆØ§Ø­Ø¯ ÙŠÙØ¹Ø§Ø¯ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡
db_pool = ChromaDBPool(CHROMA_PATH, COLLECTION_NAME, embeddings_model)

def query_db(query_text):
    return db_pool.connection.similarity_search(query_text, k=5)
```

---

### 8. **Configuration Management**

```python
# âœ… Best Practice: Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ø±ÙƒØ²ÙŠØ©
from dataclasses import dataclass
from pathlib import Path
import os

@dataclass
class AppConfig:
    """Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ©"""
    # Paths
    BASE_DIR: Path = Path(__file__).parent
    CHROMA_PATH: Path = BASE_DIR / "chroma_db"
    KNOWLEDGE_PATH: Path = BASE_DIR / "knowledge"

    # Database
    COLLECTION_NAME: str = "sfda_collection"
    EMBEDDING_MODEL: str = "intfloat/multilingual-e5-large"

    # LLM
    LLM_MODEL: str = "deepseek/deepseek-chat"
    LLM_TEMPERATURE: float = 0.0
    LLM_MAX_TOKENS: int = 700

    # Cache
    CACHE_TTL_HOURS: int = 24
    CACHE_MAX_SIZE: int = 1000

    # Rate Limiting
    MAX_REQUESTS_PER_MINUTE: int = 20
    MAX_COST_PER_HOUR: float = 1.0

    # Performance
    RETRIEVAL_TOP_K: int = 8
    RESPONSE_TIMEOUT_SEC: int = 30

    # Features
    ENABLE_CACHE: bool = True
    ENABLE_LOGGING: bool = True
    ENABLE_RATE_LIMITING: bool = True

    @classmethod
    def from_env(cls):
        """ØªØ­Ù…ÙŠÙ„ Ù…Ù† environment variables"""
        return cls(
            LLM_TEMPERATURE=float(os.getenv("LLM_TEMPERATURE", 0.0)),
            CACHE_TTL_HOURS=int(os.getenv("CACHE_TTL_HOURS", 24)),
            # ... etc
        )

# Ø§Ø³ØªØ®Ø¯Ø§Ù…:
config = AppConfig.from_env()

llm = ChatOpenAI(
    model=config.LLM_MODEL,
    temperature=config.LLM_TEMPERATURE,
    max_tokens=config.LLM_MAX_TOKENS,
)
```

---

## ğŸ¯ Ø®Ø·Ø© Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ù…ÙˆØµÙ‰ Ø¨Ù‡Ø§ (3 Ø£ÙŠØ§Ù…)

### Ø§Ù„ÙŠÙˆÙ… 1: Core Improvements
- [ ] Smart Cache Ù…Ø¹ expiration
- [ ] Query Validation & Sanitization
- [ ] Structured Logging
- [ ] Error Handling Ù…Ø­Ø³Ù‘Ù†

### Ø§Ù„ÙŠÙˆÙ… 2: Performance & Security
- [ ] Rate Limiting
- [ ] Connection Pooling
- [ ] Graceful Degradation
- [ ] Configuration Management

### Ø§Ù„ÙŠÙˆÙ… 3: Monitoring & Testing
- [ ] Performance Monitor
- [ ] Integration Testing
- [ ] Load Testing
- [ ] Documentation Update

---

## ğŸ“Š Metrics Ù„Ù„Ù†Ø¬Ø§Ø­

| Ø§Ù„Ù…Ù‚ÙŠØ§Ø³ | Ø§Ù„Ù‡Ø¯Ù | Ø§Ù„Ø­Ø§Ù„ÙŠ |
|---------|-------|--------|
| Cache Hit Rate | > 60% | 0% |
| Avg Response Time | < 500ms | ØŸ |
| Error Rate | < 1% | ØŸ |
| Cost per Query | < $0.001 | ØŸ |

---

## ğŸ”’ Security Checklist

- [ ] Input validation
- [ ] Rate limiting
- [ ] API key rotation
- [ ] Logging (Ù„Ø§ ØªØ­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø§Ø³Ø©)
- [ ] HTTPS only (ÙÙŠ production)
- [ ] CORS configuration
- [ ] SQL injection prevention (N/A - Ù†Ø³ØªØ®Ø¯Ù… ChromaDB)
- [ ] XSS prevention

---

## ğŸ“š Resources

- [LangChain Best Practices](https://python.langchain.com/docs/guides/productionization/)
- [Gradio Security Guide](https://www.gradio.app/guides/security-and-file-access)
- [ChromaDB Production Guide](https://docs.trychroma.com/deployment)

---

**Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ«:** 2026-01-31
**Ø§Ù„Ø­Ø§Ù„Ø©:** Ready for Implementation âœ…
