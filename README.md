# SANAD - SFDA Cosmetics Compliance Chatbot

An intelligent Arabic chatbot for querying Saudi Food and Drug Authority (SFDA) cosmetics regulations and banned substances using Retrieval Augmented Generation (RAG).

## Features

- ğŸ¤– Arabic language support with intelligent text processing
- ğŸ“š Multi-source knowledge base (PDF, JSON, JSONL, Excel)
- ğŸ” Smart retrieval of regulations and banned substances
- ğŸ’¬ Natural language question answering
- ğŸ¯ Direct article lookup by number
- ğŸŒ Web interface using Gradio
- ğŸ§  Vector embeddings using multilingual-e5-large
- âš¡ Streaming responses for better UX

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Query     â”‚
â”‚  (Arabic)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Gradio UI      â”‚
â”‚  (Web Interface)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SFDAChatbot    â”‚
â”‚  (RAG Logic)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â–¼         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Chroma  â”‚ â”‚OpenRouterâ”‚
â”‚Vector  â”‚ â”‚LLM       â”‚
â”‚Store   â”‚ â”‚(DeepSeek)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Project Structure

```
smart_chatbot/
â”œâ”€â”€ config.py                      # Centralized configuration
â”œâ”€â”€ app_gradio.py                  # Original Gradio application
â”œâ”€â”€ app_gradio_improved.py         # Improved version with better structure
â”œâ”€â”€ ingest_database.py             # Original database ingestion
â”œâ”€â”€ ingest_database_improved.py    # Improved version with logging
â”œâ”€â”€ build_chroma_from_json.py      # Build ChromaDB from JSON
â”œâ”€â”€ ingest_from_json_dict.py       # Ingest from JSON dictionary format
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ .env.example                   # Environment variables template
â”œâ”€â”€ .gitignore                     # Git ignore rules
â”œâ”€â”€ knowledge/                     # Knowledge base directory
â”‚   â”œâ”€â”€ sfda_articles.json        # SFDA regulations (Arabic)
â”‚   â”œâ”€â”€ banned_list.json          # Banned substances list
â”‚   â””â”€â”€ *.xlsx                    # Excel files with data
â”œâ”€â”€ chroma_db/                     # ChromaDB vector store (generated)
â””â”€â”€ scripts/                       # Utility scripts
    â”œâ”€â”€ clean_flat_json.py
    â”œâ”€â”€ clean_text.py
    â”œâ”€â”€ ingest_to_chroma.py
    â”œâ”€â”€ prepare_chunks.py
    â”œâ”€â”€ query_filtered.py
    â””â”€â”€ rag_answer.py
```

## Prerequisites

- Python 3.9 or higher
- OpenRouter API key (for LLM access)
- 4GB+ RAM recommended
- Windows/Linux/MacOS

## Installation

### 1. Clone the repository

```bash
git clone <repository-url>
cd smart_chatbot
```

### 2. Create virtual environment

```bash
# Windows
python -m venv .venv
.venv\Scripts\activate

# Linux/Mac
python3 -m venv .venv
source .venv/bin/activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Configure environment variables

```bash
# Copy the example file
cp .env.example .env

# Edit .env and add your API key
# OPENROUTER_API_KEY=your_api_key_here
```

Get your OpenRouter API key from: https://openrouter.ai/keys

### 5. Prepare knowledge base

Place your knowledge files in the `knowledge/` directory:
- `sfda_articles.json` - SFDA regulations in JSON format
- `banned_list.json` - Banned substances list
- `*.xlsx` - Excel files with cosmetics data

### 6. Ingest data into vector store

```bash
# Use the improved version with logging
python ingest_database_improved.py

# Or use the original version
python ingest_database.py
```

This will:
- Load documents from `knowledge/` directory
- Process and chunk the text
- Generate embeddings using multilingual-e5-large
- Store in ChromaDB vector database

### 7. Run the application

```bash
# Use the improved version
python app_gradio_improved.py

# Or use the original version
python app_gradio.py
```

The application will:
- Load the vector store
- Initialize the LLM
- Launch a Gradio web interface
- Provide a shareable public URL

## Usage

### Web Interface

1. Open the Gradio interface in your browser
2. Select the search source:
   - **Ù„ÙˆØ§Ø¦Ø­ Ø§Ù„ØªØ¬Ù…ÙŠÙ„ (PDF)** - SFDA regulations
   - **Ù…Ø­Ø¸ÙˆØ±Ø§Øª Ø§Ù„ØªØ¬Ù…ÙŠÙ„** - Banned substances
   - **Ø§Ù„ÙƒÙ„** - All sources
3. Type your question in Arabic
4. View the streaming response with sources

### Example Queries

**Regulations:**
- "Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ø±Ø§Ø¨Ø¹Ø©ØŸ" (What is Article 4?)
- "Ø§Ø°ÙƒØ± Ø§Ù„ØªØ²Ø§Ù…Ø§Øª Ø§Ù„Ù…ÙØ¯Ø±Ø¬ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…" (List the obligations of the registrant)

**Banned Substances:**
- "Ù‡Ù„ Mercury Ù…Ø­Ø¸ÙˆØ± ÙÙŠ Ø§Ù„ØªØ¬Ù…ÙŠÙ„ØŸ" (Is Mercury banned in cosmetics?)
- "Ø§Ø°ÙƒØ± Ù„ÙŠ 5 Ù…ÙˆØ§Ø¯ Ù…Ø­Ø¸ÙˆØ±Ø© ØªØ¨Ø¯Ø£ Ø¨Ø­Ø±Ù M" (List 5 banned substances starting with M)

## Configuration

All configuration is centralized in `config.py`. You can override settings using environment variables in `.env`:

### Database Configuration
- `CHROMA_PATH` - Vector store directory (default: chroma_db)
- `COLLECTION_NAME` - Collection name (default: sfda_collection)
- `DATA_PATH` - Knowledge base directory (default: knowledge)

### Model Configuration
- `EMBEDDING_MODEL` - Embedding model (default: intfloat/multilingual-e5-large)
- `EMBEDDING_DEVICE` - Device for embeddings (default: cpu)
- `LLM_MODEL` - LLM model (default: deepseek/deepseek-chat)
- `LLM_TEMPERATURE` - Response randomness (default: 0.0)
- `LLM_MAX_TOKENS` - Maximum response length (default: 700)

### RAG Configuration
- `RETRIEVAL_K` - Number of documents to retrieve (default: 8)
- `CHUNK_SIZE` - Text chunk size (default: 1000)
- `CHUNK_OVERLAP` - Chunk overlap (default: 150)
- `BATCH_SIZE` - ChromaDB batch size (default: 2000)

### Application Configuration
- `DEBUG` - Enable debug mode (default: False)

## Key Improvements in Enhanced Version

### Code Quality
âœ… Type hints on all functions
âœ… Comprehensive docstrings
âœ… Proper error handling with try-catch blocks
âœ… Logging system for debugging
âœ… Class-based organization

### Configuration
âœ… Centralized config.py
âœ… Environment variable support
âœ… Configuration validation

### Error Handling
âœ… Graceful error recovery
âœ… User-friendly error messages
âœ… Detailed logging for debugging

### Performance
âœ… Efficient batch processing
âœ… Optimized text processing
âœ… Connection pooling ready

### Maintainability
âœ… Separation of concerns
âœ… Reusable components
âœ… Clear code structure
âœ… Documentation

## Troubleshooting

### API Key Error
```
ValueError: OPENROUTER_API_KEY not found in .env file
```
**Solution:** Create a `.env` file and add your OpenRouter API key.

### ChromaDB Not Found
```
FileNotFoundError: Chroma database not found
```
**Solution:** Run `python ingest_database_improved.py` to create the vector store.

### Empty Results
**Solution:**
- Check if knowledge files exist in `knowledge/` directory
- Verify the vector store has documents (check logs)
- Try broader queries

### Encoding Issues
**Solution:** Ensure all files are saved in UTF-8 encoding.

### Memory Issues
**Solution:**
- Reduce `CHUNK_SIZE` in config
- Reduce `BATCH_SIZE` for ingestion
- Use a smaller embedding model

## Development

### Adding New Features

1. Create a feature branch
2. Implement with proper type hints and docstrings
3. Add error handling
4. Test thoroughly
5. Update documentation

### Code Style

- Follow PEP 8 guidelines
- Use type hints
- Add docstrings (Google style)
- Keep functions focused and small
- Use meaningful variable names

### Testing

```bash
# Run the application in debug mode
DEBUG=True python app_gradio_improved.py
```

## Performance Optimization

### Embedding Model
- Current: `intfloat/multilingual-e5-large` (1.12GB)
- Alternative: `intfloat/multilingual-e5-base` (560MB, faster)
- Alternative: `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2` (420MB, fastest)

### LLM Model
- Current: `deepseek/deepseek-chat` (cost-effective)
- Alternative: `gpt-4o-mini` (faster, more expensive)
- Alternative: `gpt-3.5-turbo` (cheaper, less capable)

## Security Considerations

- âœ… API keys in environment variables
- âœ… .env file in .gitignore
- âš ï¸ Add input validation for production
- âš ï¸ Add rate limiting for public deployment
- âš ï¸ Sanitize user inputs

## License

[Specify your license here]

## Contributors

[List contributors here]

## Support

For issues and questions:
- Create an issue on GitHub
- Contact: [your-email@example.com]

## Acknowledgments

- SFDA for regulations data
- LangChain for RAG framework
- Gradio for UI framework
- HuggingFace for embedding models
- OpenRouter for LLM access

## Changelog

### Version 2.0 (Improved)
- Added centralized configuration
- Improved error handling and logging
- Better code organization with classes
- Type hints and comprehensive docstrings
- Enhanced documentation

### Version 1.0 (Original)
- Basic RAG implementation
- Gradio web interface
- Multi-source document support
- Arabic text processing
