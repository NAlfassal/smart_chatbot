"""
Improved Gradio Application for SFDA Cosmetics Chatbot.

ÙˆØ§Ø¬Ù‡Ø© Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¹Ù†:
- Ù„ÙˆØ§Ø¦Ø­ Ø§Ù„ØªØ¬Ù…ÙŠÙ„ (PDF)       category=regulation
- Ù…Ø­Ø¸ÙˆØ±Ø§Øª Ø§Ù„ØªØ¬Ù…ÙŠÙ„          category=banned
- Ø§Ù„Ø£Ø³Ø³ (GDP)              category=gdp

Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… RAG (Retrieval Augmented Generation)
"""

import os
import re
import logging
from typing import List, Optional, Iterator

import gradio as gr
from langchain_openai import ChatOpenAI
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain_core.documents import Document
from langchain_core.messages import HumanMessage

import config

# ---------------------------------------------------------------------
# Logging
# ---------------------------------------------------------------------
logging.basicConfig(
    level=logging.INFO if getattr(config, "DEBUG", False) else logging.WARNING,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


# ---------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------
class ArabicArticleParser:
    """Handles parsing and conversion of Arabic article numbers."""

    AR_WORD_TO_NUM = {
        "Ø§Ù„Ø£ÙˆÙ„Ù‰": "1", "Ø§Ù„Ø§ÙˆÙ„Ù‰": "1",
        "Ø§Ù„Ø«Ø§Ù†ÙŠØ©": "2",
        "Ø§Ù„Ø«Ø§Ù„Ø«Ø©": "3",
        "Ø§Ù„Ø±Ø§Ø¨Ø¹Ø©": "4",
        "Ø§Ù„Ø®Ø§Ù…Ø³Ø©": "5",
        "Ø§Ù„Ø³Ø§Ø¯Ø³Ø©": "6",
        "Ø§Ù„Ø³Ø§Ø¨Ø¹Ø©": "7",
        "Ø§Ù„Ø«Ø§Ù…Ù†Ø©": "8",
        "Ø§Ù„ØªØ§Ø³Ø¹Ø©": "9",
        "Ø§Ù„Ø¹Ø§Ø´Ø±Ø©": "10",
        "Ø§Ù„Ø­Ø§Ø¯ÙŠØ© Ø¹Ø´Ø±": "11", "Ø§Ù„Ø­Ø§Ø¯ÙŠØ© Ø¹Ø´Ø±Ø©": "11",
        "Ø§Ù„Ø«Ø§Ù†ÙŠØ© Ø¹Ø´Ø±": "12", "Ø§Ù„Ø«Ø§Ù†ÙŠØ© Ø¹Ø´Ø±Ø©": "12",
        "Ø§Ù„Ø«Ø§Ù„Ø«Ø© Ø¹Ø´Ø±": "13", "Ø§Ù„Ø«Ø§Ù„Ø«Ø© Ø¹Ø´Ø±Ø©": "13",
        "Ø§Ù„Ø±Ø§Ø¨Ø¹Ø© Ø¹Ø´Ø±": "14", "Ø§Ù„Ø±Ø§Ø¨Ø¹Ø© Ø¹Ø´Ø±Ø©": "14",
        "Ø§Ù„Ø®Ø§Ù…Ø³Ø© Ø¹Ø´Ø±": "15", "Ø§Ù„Ø®Ø§Ù…Ø³Ø© Ø¹Ø´Ø±Ø©": "15",
        "Ø§Ù„Ø³Ø§Ø¯Ø³Ø© Ø¹Ø´Ø±": "16", "Ø§Ù„Ø³Ø§Ø¯Ø³Ø© Ø¹Ø´Ø±Ø©": "16",
        "Ø§Ù„Ø³Ø§Ø¨Ø¹Ø© Ø¹Ø´Ø±": "17", "Ø§Ù„Ø³Ø§Ø¨Ø¹Ø© Ø¹Ø´Ø±Ø©": "17",
        "Ø§Ù„Ø«Ø§Ù…Ù†Ø© Ø¹Ø´Ø±": "18", "Ø§Ù„Ø«Ø§Ù…Ù†Ø© Ø¹Ø´Ø±Ø©": "18",
        "Ø§Ù„ØªØ§Ø³Ø¹Ø© Ø¹Ø´Ø±": "19", "Ø§Ù„ØªØ§Ø³Ø¹Ø© Ø¹Ø´Ø±Ø©": "19",
        "Ø§Ù„Ø¹Ø´Ø±ÙˆÙ†": "20",
        "Ø§Ù„Ø­Ø§Ø¯ÙŠØ© ÙˆØ§Ù„Ø¹Ø´Ø±ÙˆÙ†": "21",
        "Ø§Ù„Ø«Ø§Ù†ÙŠØ© ÙˆØ§Ù„Ø¹Ø´Ø±ÙˆÙ†": "22",
        "Ø§Ù„Ø«Ø§Ù„Ø«Ø© ÙˆØ§Ù„Ø¹Ø´Ø±ÙˆÙ†": "23",
        "Ø§Ù„Ø±Ø§Ø¨Ø¹Ø© ÙˆØ§Ù„Ø¹Ø´Ø±ÙˆÙ†": "24",
        "Ø§Ù„Ø®Ø§Ù…Ø³Ø© ÙˆØ§Ù„Ø¹Ø´Ø±ÙˆÙ†": "25",
        "Ø§Ù„Ø³Ø§Ø¯Ø³Ø© ÙˆØ§Ù„Ø¹Ø´Ø±ÙˆÙ†": "26",
        "Ø§Ù„Ø³Ø§Ø¨Ø¹Ø© ÙˆØ§Ù„Ø¹Ø´Ø±ÙˆÙ†": "27",
        "Ø§Ù„Ø«Ø§Ù…Ù†Ø© ÙˆØ§Ù„Ø¹Ø´Ø±ÙˆÙ†": "28",
        "Ø§Ù„ØªØ§Ø³Ø¹Ø© ÙˆØ§Ù„Ø¹Ø´Ø±ÙˆÙ†": "29",
        "Ø§Ù„Ø«Ù„Ø§Ø«ÙˆÙ†": "30",
    }

    @classmethod
    def normalize_article_to_num(cls, article_value: str) -> Optional[str]:
        if article_value is None:
            return None

        s = str(article_value).strip()
        s = s.replace("Ù€", "")
        s = re.sub(r"\s{2,}", " ", s)
        s = re.sub(r"^\s*Ø§Ù„Ù…Ø§Ø¯Ø©\s+", "", s).strip()

        if re.fullmatch(r"\d+", s):
            return s

        if s in cls.AR_WORD_TO_NUM:
            return cls.AR_WORD_TO_NUM[s]

        words = s.split()
        for n in (4, 3, 2, 1):
            if len(words) >= n:
                cand = " ".join(words[:n])
                if cand in cls.AR_WORD_TO_NUM:
                    return cls.AR_WORD_TO_NUM[cand]
        return None

    @classmethod
    def extract_article_number(cls, text: str) -> Optional[str]:
        text = text or ""

        m = re.search(r"Ø§Ù„Ù…Ø§Ø¯Ø©\s+(\d+)", text)
        if m:
            return m.group(1)

        m = re.search(r"Ø§Ù„Ù…Ø§Ø¯Ø©\s+([^\nØŒ,.ØŸ!]+)", text)
        if not m:
            return None

        phrase = re.sub(r"\s{2,}", " ", m.group(1).replace("Ù€", "")).strip()
        phrase = re.sub(r"^\s*Ø§Ù„Ù…Ø§Ø¯Ø©\s+", "", phrase).strip()

        if phrase in cls.AR_WORD_TO_NUM:
            return cls.AR_WORD_TO_NUM[phrase]

        words = phrase.split()
        for n in (4, 3, 2, 1):
            if len(words) >= n:
                cand = " ".join(words[:n])
                if cand in cls.AR_WORD_TO_NUM:
                    return cls.AR_WORD_TO_NUM[cand]
        return None


class TextFormatter:
    """Handles text formatting and cleaning operations."""

    @staticmethod
    def clean_repeated_characters(text: str) -> str:
        return re.sub(r"(.)\1{2,}", r"\1", text or "")

    @staticmethod
    def merge_spaced_arabic_letters(text: str) -> str:
        if not text:
            return ""
        t = text
        for _ in range(3):
            t = re.sub(
                r"(?<![Ø¡-ÙŠ])((?:[Ø¡-ÙŠ]\s+){2,}[Ø¡-ÙŠ])(?![Ø¡-ÙŠ])",
                lambda m: m.group(1).replace(" ", ""),
                t,
            )
        return t

    @staticmethod
    def pretty_arabic_text(text: str) -> str:
        if not text:
            return ""
        t = TextFormatter.merge_spaced_arabic_letters(text)
        t = t.replace("\r\n", "\n").replace("\r", "\n")
        t = t.replace("Ù€", "")
        t = re.sub(r"[ \t]+", " ", t)
        t = re.sub(r"\n{3,}", "\n\n", t)
        return t.strip()


class SourceDisplayManager:
    """Display sources based on metadata category (NOT filename)."""

    @staticmethod
    def display_source_name_from_doc(doc: Document) -> str:
        cat = (doc.metadata.get("category") or "").lower().strip()

        if cat == "banned":
            return "Ù…Ø­Ø¸ÙˆØ±Ø§Øª Ø§Ù„ØªØ¬Ù…ÙŠÙ„"
        if cat == "regulation":
            return "Ù„ÙˆØ§Ø¦Ø­ Ø§Ù„ØªØ¬Ù…ÙŠÙ„"
        if cat in ("gdp", "guidelines", "gdp_guidelines"):
            return "Ø§Ù„Ø£Ø³Ø³ (Ø§Ù„ØªÙˆØ²ÙŠØ¹ ÙˆØ§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø¬ÙŠØ¯Ø©)"

        raw = doc.metadata.get("source", doc.metadata.get("source_file", "N/A"))
        return os.path.basename(raw or "N/A").strip() or "Ù…ØµØ§Ø¯Ø± Ø¥Ø¶Ø§ÙÙŠØ©"

    @staticmethod
    def sources_footer_once(docs: List[Document], chosen_sources_ui: List[str]) -> str:
        if chosen_sources_ui and set(chosen_sources_ui) == {"Ù…Ø­Ø¸ÙˆØ±Ø§Øª Ø§Ù„ØªØ¬Ù…ÙŠÙ„"}:
            return "\n\n**Ø§Ù„Ù…ØµØ¯Ø±:** Ù…Ø­Ø¸ÙˆØ±Ø§Øª Ø§Ù„ØªØ¬Ù…ÙŠÙ„"

        seen = set()
        sources = []
        for d in docs:
            name = SourceDisplayManager.display_source_name_from_doc(d)
            if name and name not in seen:
                seen.add(name)
                sources.append(name)

        return "\n\n**Ø§Ù„Ù…ØµØ¯Ø±:** " + ("ØŒ ".join(sources) if sources else "N/A")


# ---------------------------------------------------------------------
# Main Chatbot
# ---------------------------------------------------------------------
class SFDAChatbot:
    """Main chatbot class handling RAG operations."""

    def __init__(self):
        logger.info("Initializing SFDA Chatbot...")

        if not getattr(config, "OPENROUTER_API_KEY", None):
            raise ValueError("OPENROUTER_API_KEY not found in .env file")

        logger.info("Loading embedding model...")
        self.embeddings_model = HuggingFaceEmbeddings(
            model_name=config.EMBEDDING_MODEL,
            model_kwargs={"device": config.EMBEDDING_DEVICE},
        )

        logger.info("Initializing LLM...")
        self.llm = ChatOpenAI(
            model=config.LLM_MODEL,
            temperature=config.LLM_TEMPERATURE,
            api_key=config.OPENROUTER_API_KEY,
            base_url=config.LLM_BASE_URL,
            max_tokens=config.LLM_MAX_TOKENS,
        )

        logger.info("Loading vector store...")
        self.vector_store = Chroma(
            collection_name=config.COLLECTION_NAME,
            embedding_function=self.embeddings_model,
            persist_directory=config.CHROMA_PATH,
        )

        try:
            count = self.vector_store._collection.count()
            logger.info(f"Vector store loaded. Document count: {count}")
        except Exception as e:
            logger.warning(f"Could not get vector store count: {e}")

        logger.info("âœ… Chatbot initialized successfully")

    def get_article_doc(self, article_num: str) -> Optional[Document]:
        target = str(article_num).strip()

        try:
            docs = self.vector_store.similarity_search(
                query=f"Ø§Ù„Ù…Ø§Ø¯Ø© {target}",
                k=3,
                filter={"$and": [{"article": target}, {"category": "regulation"}]},
            )
            if docs:
                return docs[0]
        except Exception as e:
            logger.debug(f"Regulation filter search failed: {e}")

        try:
            docs = self.vector_store.similarity_search(
                query=f"Ø§Ù„Ù…Ø§Ø¯Ø© {target}",
                k=3,
                filter={"article": target},
            )
            if docs:
                return docs[0]
        except Exception as e:
            logger.debug(f"Article filter search failed: {e}")

        return None

    def format_article_output(self, doc: Document) -> str:
        art_num = ArabicArticleParser.normalize_article_to_num(doc.metadata.get("article", "")) or ""
        title = f"Ù†Øµ Ø§Ù„Ù…Ø§Ø¯Ø© ({art_num}) Ù…Ù† Ù„ÙˆØ§Ø¦Ø­ Ø§Ù„ØªØ¬Ù…ÙŠÙ„" if art_num else "Ù†Øµ Ø§Ù„Ù…Ø§Ø¯Ø© Ù…Ù† Ù„ÙˆØ§Ø¦Ø­ Ø§Ù„ØªØ¬Ù…ÙŠÙ„"
        body = TextFormatter.pretty_arabic_text(doc.page_content)

        if art_num:
            body = re.sub(rf"^\s*Ø§Ù„Ù…Ø§Ø¯Ø©\s*{re.escape(art_num)}\s*\n+", "", body)
            body = re.sub(rf"^\s*Ø§Ù„Ù…Ø§Ø¯Ø©\s*{re.escape(art_num)}\s*[:ï¼š]?\s*", "", body)

        return f"**{title}**\n\n{body}".strip()

    def build_retriever(self, ui_choices: List[str]):
        if not ui_choices:
            return self.vector_store.as_retriever(search_kwargs={"k": config.RETRIEVAL_K})

        selected_categories = []
        for ch in ui_choices:
            if ch == "Ù„ÙˆØ§Ø¦Ø­ Ø§Ù„ØªØ¬Ù…ÙŠÙ„ (PDF)":
                selected_categories.append("regulation")
            elif ch == "Ù…Ø­Ø¸ÙˆØ±Ø§Øª Ø§Ù„ØªØ¬Ù…ÙŠÙ„":
                selected_categories.append("banned")
            elif ch == "Ø§Ù„Ø£Ø³Ø³ (GDP)":
                selected_categories.append("gdp")

        if not selected_categories or len(selected_categories) >= 3:
            return self.vector_store.as_retriever(search_kwargs={"k": config.RETRIEVAL_K})

        or_filter = {"$or": [{"category": c} for c in selected_categories]}
        return self.vector_store.as_retriever(
            search_kwargs={"k": config.RETRIEVAL_K, "filter": or_filter}
        )

    @staticmethod
    def build_knowledge(docs: List[Document]) -> str:
        parts = []
        for d in docs:
            src = SourceDisplayManager.display_source_name_from_doc(d)
            snippet = TextFormatter.pretty_arabic_text(d.page_content)[:1400]
            parts.append(f"[{src}]\n{snippet}")
        return "\n\n".join(parts)

    def stream_response_core(self, message: str, source_choices: List[str]) -> Iterator[str]:
        message = (message or "").strip()
        if not message:
            yield "Ø§ÙƒØªØ¨ÙŠ Ø³Ø¤Ø§Ù„Ùƒ."
            return

        try:
            art_num = ArabicArticleParser.extract_article_number(message)
            if art_num:
                if source_choices and set(source_choices) == {"Ù…Ø­Ø¸ÙˆØ±Ø§Øª Ø§Ù„ØªØ¬Ù…ÙŠÙ„"}:
                    yield "Ø¹Ø°Ø±Ù‹Ø§ØŒ Ø³Ø¤Ø§Ù„ **Ø§Ù„Ù…Ø§Ø¯Ø© (Ù…Ø«Ù„ Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ø±Ø§Ø¨Ø¹Ø©)** ÙŠÙƒÙˆÙ† Ø¶Ù…Ù† **Ù„ÙˆØ§Ø¦Ø­ Ø§Ù„ØªØ¬Ù…ÙŠÙ„ (PDF)**. ÙØ¹Ù‘Ù„ÙŠ Ø®ÙŠØ§Ø± Ø§Ù„Ù„ÙˆØ§Ø¦Ø­."
                    return

                doc = self.get_article_doc(art_num)
                if not doc:
                    yield f"Ø¹Ø°Ø±Ù‹Ø§ØŒ Ù„Ù… Ø£Ø¬Ø¯ Ù†ØµÙ‹Ø§ ØµØ±ÙŠØ­Ù‹Ø§ Ù„Ù„Ù…Ø§Ø¯Ø© Ø±Ù‚Ù… {art_num} Ø¯Ø§Ø®Ù„ Ù„ÙˆØ§Ø¦Ø­ Ø§Ù„ØªØ¬Ù…ÙŠÙ„."
                    return

                answer = self.format_article_output(doc)
                answer += SourceDisplayManager.sources_footer_once([doc], source_choices)
                yield answer
                return

            retriever = self.build_retriever(source_choices)
            retrieved_docs = retriever.invoke("query: " + message)

            if not retrieved_docs:
                yield "Ù„Ù… Ø£Ø¬Ø¯ Ù†ØµÙ‹Ø§ ØµØ±ÙŠØ­Ù‹Ø§ ÙÙŠ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…ØªØ§Ø­Ø© ÙŠØ¬ÙŠØ¨ Ø¹Ù† Ø°Ù„Ùƒ."
                return

            top_docs = retrieved_docs[:3]
            knowledge = self.build_knowledge(top_docs)

            generation_prompt = f"""
ROLE:
Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù…ØªØ«Ø§Ù„ ÙŠØ¹ØªÙ…Ø¯ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø±ÙÙ‚Ø©.

RULES (Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹):
- Ù„Ø§ ØªØ¶Ù Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø© Ù…Ù† Ø®Ø§Ø±Ø¬ "Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©".
- Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ù†ØµØ§Ù‹ ØµØ±ÙŠØ­Ø§Ù‹ ÙŠØ¬ÙŠØ¨ Ø¹Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ØŒ Ù‚Ù„: "Ù„Ù… Ø£Ø¬Ø¯ Ù†ØµØ§Ù‹ ØµØ±ÙŠØ­Ø§Ù‹ ÙÙŠ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…Ø±ÙÙ‚Ø© ÙŠØ¬ÙŠØ¨ Ø¹Ù† Ø°Ù„Ùƒ."
- Ø§ÙƒØªØ¨ Ø¥Ø¬Ø§Ø¨Ø© Ù‚ØµÙŠØ±Ø© ÙˆÙ…Ù†Ø¸Ù…Ø© Ø¨Ù†Ù‚Ø§Ø·.
- Ù„Ø§ ØªØ°ÙƒØ± Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø¯Ø§Ø®Ù„ Ø§Ù„Ù†Øµ (Ø³Ø£Ø¶ÙŠÙÙ‡Ø§ Ø£Ù†Ø§ ÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ©).

----
Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©:
{knowledge}

Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {message}

Ø§ÙƒØªØ¨ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ø¢Ù†:
""".strip()

            final_answer = ""
            for chunk in self.llm.stream([HumanMessage(content=generation_prompt)]):
                if getattr(chunk, "content", None):
                    final_answer += chunk.content
                    final_answer = TextFormatter.clean_repeated_characters(final_answer)
                    yield final_answer

            final_answer = final_answer.strip()
            final_answer += SourceDisplayManager.sources_footer_once(top_docs, source_choices)
            yield final_answer

        except Exception as e:
            logger.error(f"Error generating response: {e}")
            yield "Ø¹Ø°Ø±Ù‹Ø§ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø³Ø¤Ø§Ù„Ùƒ. Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰."


# ---------------------------------------------------------------------
# UI (Gradio)
# ---------------------------------------------------------------------
def create_gradio_interface(chatbot: SFDAChatbot) -> gr.Blocks:
    css_code = """.gradio-container { font-family: Tahoma, sans-serif; }"""

    try:
        theme = gr.themes.Soft(primary_hue="blue")
    except Exception:
        theme = None

    with gr.Blocks(css=css_code, theme=theme) as demo:
        gr.Markdown("# SANAD")
        gr.Markdown("Ø§Ø®ØªØ§Ø±ÙŠ **Ù…ØµØ¯Ø±/Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø¨Ø­Ø«** Ø«Ù… Ø§ÙƒØªØ¨ÙŠ Ø³Ø¤Ø§Ù„Ùƒ ÙˆØ§Ø¶ØºØ·ÙŠ **Ø¥Ø±Ø³Ø§Ù„**.")

        source_choices = gr.CheckboxGroup(
            choices=["Ù„ÙˆØ§Ø¦Ø­ Ø§Ù„ØªØ¬Ù…ÙŠÙ„ (PDF)", "Ù…Ø­Ø¸ÙˆØ±Ø§Øª Ø§Ù„ØªØ¬Ù…ÙŠÙ„", "Ø§Ù„Ø£Ø³Ø³ (GDP)"],
            value=["Ù„ÙˆØ§Ø¦Ø­ Ø§Ù„ØªØ¬Ù…ÙŠÙ„ (PDF)"],
            label="Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø¨Ø­Ø« (Ø§Ø®ØªÙŠØ§Ø± ÙˆØ§Ø­Ø¯ Ø£Ùˆ Ø£ÙƒØ«Ø±)",
        )

        chat = gr.Chatbot(label="Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©", height=520)
        state = gr.State([])  # messages history

        with gr.Row():
            msg = gr.Textbox(
                placeholder="Ø§ÙƒØªØ¨ÙŠ Ø³Ø¤Ø§Ù„Ùƒ...",
                label="",
                show_label=False,
                scale=8,
            )
            send = gr.Button("Ø¥Ø±Ø³Ø§Ù„", variant="primary", scale=2)

        clear = gr.Button("Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©")

        def ensure_text(x) -> str:
            if isinstance(x, list):
                return " ".join([str(i) for i in x])
            return str(x) if x is not None else ""

        def add_user(user_message, history_state):
            user_message = ensure_text(user_message).strip()
            history_state = history_state or []

            if not user_message:
                return gr.update(value=""), history_state, history_state

            history_state = history_state + [
                {"role": "user", "content": user_message},
                {"role": "assistant", "content": ""},
            ]
            return gr.update(value=""), history_state, history_state

        def stream_bot(history_state, choices):
            history_state = history_state or []

            user_message = ""
            for i in range(len(history_state) - 1, -1, -1):
                if history_state[i].get("role") == "user":
                    user_message = history_state[i].get("content", "")
                    break

            last_assistant_idx = None
            for i in range(len(history_state) - 1, -1, -1):
                if history_state[i].get("role") == "assistant":
                    last_assistant_idx = i
                    break

            for chunk in chatbot.stream_response_core(user_message, choices):
                if last_assistant_idx is not None:
                    history_state[last_assistant_idx]["content"] = chunk
                yield history_state, history_state

        send.click(
            fn=add_user,
            inputs=[msg, state],
            outputs=[msg, state, chat],
        ).then(
            fn=stream_bot,
            inputs=[state, source_choices],
            outputs=[chat, state],
        )

        msg.submit(
            fn=add_user,
            inputs=[msg, state],
            outputs=[msg, state, chat],
        ).then(
            fn=stream_bot,
            inputs=[state, source_choices],
            outputs=[chat, state],
        )

        def clear_all():
            return [], []

        clear.click(fn=clear_all, inputs=None, outputs=[chat, state])

        # -----------------------------------------------------------------
        # âœ… ØªØ¹Ø¯ÙŠÙ„ "Ø¬Ø²Ø¦ÙŠØ© Ø§Ù„Ø£Ø³Ø¦Ù„Ø©" ÙÙ‚Ø·:
        # - Ø­Ø°Ù Ø§Ù„Ø£Ù…Ø«Ù„Ø© ØªØ­Øª
        # - Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø¯Ø§Ø®Ù„ Ø§Ù„Ø´Ø§Øª Ø¹Ù†Ø¯ ÙØªØ­ Ø§Ù„ØµÙØ­Ø©
        # -----------------------------------------------------------------
        initial_examples = (
            "ğŸ‘‹ **Ø£Ù…Ø«Ù„Ø© Ø¬Ø§Ù‡Ø²Ø© (Ø§Ù†Ø³Ø®ÙŠ/Ø§Ù„ØµÙ‚ÙŠ Ø³Ø¤Ø§Ù„Ø§Ù‹ Ø£Ùˆ Ø§ÙƒØªØ¨ÙŠÙ‡):**\n\n"
            "â€¢ Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ø±Ø§Ø¨Ø¹Ø©ØŸ\n"
            "â€¢ Ø§Ø°ÙƒØ± Ø§Ù„ØªØ²Ø§Ù…Ø§Øª Ø§Ù„Ù…ÙØ¯Ø±Ø¬ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…\n"
            "â€¢ Ù‡Ù„ Mercury Ù…Ø­Ø¸ÙˆØ± ÙÙŠ Ø§Ù„ØªØ¬Ù…ÙŠÙ„ØŸ\n"
            "â€¢ Ø§Ø°ÙƒØ± Ù„ÙŠ 5 Ù…ÙˆØ§Ø¯ Ù…Ø­Ø¸ÙˆØ±Ø© ØªØ¨Ø¯Ø£ Ø¨Ø­Ø±Ù M\n"
            "â€¢ Ù…Ø§ Ù‡ÙŠ Ù…ØªØ·Ù„Ø¨Ø§Øª Ø¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø© ÙˆØ§Ù„Ø±Ø·ÙˆØ¨Ø© ÙÙŠ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹Ø§ØªØŸ\n"
        )

        def init_chat():
            history = [{"role": "assistant", "content": initial_examples}]
            return history, history

        demo.load(fn=init_chat, inputs=None, outputs=[chat, state])

    return demo


def main():
    try:
        bot = SFDAChatbot()
        demo = create_gradio_interface(bot)
        demo.queue().launch(
            share=True,
            show_error=True,
            debug=getattr(config, "DEBUG", False),
        )
    except Exception as e:
        logger.error(f"Failed to start application: {e}")
        raise


if __name__ == "__main__":
    main()
